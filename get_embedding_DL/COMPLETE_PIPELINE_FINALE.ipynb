{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_skip=True\n",
    "do_plot=True\n",
    "do_stats_plot=True\n",
    "do_optional_plots=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import set_random_seed, mk_dir\n",
    "from importlib import import_module\n",
    "\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ion() \n",
    "\n",
    "def save_img(tensor, name, norm, n_rows=16, scale_each=False):\n",
    "    save_image(tensor, name, nrow=n_rows, padding=5, normalize=norm, pad_value=1, scale_each=scale_each)\n",
    "    \n",
    "def plot_10_patches(img_np, true_vessel_np=False, indexes=None):\n",
    "    \n",
    "    random_indexes = np.random.randint(0, img_np.shape[0], size=5) if indexes is None else indexes\n",
    "\n",
    "    n = len(random_indexes)\n",
    "    \n",
    "    fig, ax = plt.subplots(n, 2, figsize=(6, 3*n))\n",
    "    \n",
    "    for i, index in enumerate(random_indexes):\n",
    "        \n",
    "        if index == img_np.shape[0]:\n",
    "            index -= 1\n",
    "        if index == img_np.shape[0]-1:\n",
    "            index -= 2\n",
    "            \n",
    "        #print(f\"Shape: {img_np[index,:,:].shape}, Max: {img_np[index,:,:].max()}, Min: {img_np[index,:,:].min()}\")\n",
    "        ax[i, 0].set_title(f'True Vessel Slice {index}')\n",
    "        ax[i, 0].imshow(img_np[index,:,:], cmap='gray', vmin=0, vmax=1)\n",
    "        ax[i,0].axis('off')\n",
    "        \n",
    "        if true_vessel_np is not False:\n",
    "            print(f\"Shape: {true_vessel_np[index,:,:].shape}, Max: {true_vessel_np[index,:,:].max()}, Min: {true_vessel_np[index,:,:].min()}\")\n",
    "            ax[i, 1].imshow(true_vessel_np[index,:,:], cmap='gray')\n",
    "            ax[i, 1].set_title(f'Image Slice {index}')\n",
    "        else:\n",
    "            ax[i, 1].set_title(f'Image Slice {index+1}')\n",
    "            ax[i, 1].imshow(img_np[index+1,:,:], cmap='gray', vmin=0, vmax=1)\n",
    "        \n",
    "        ax[i,1].axis('off')\n",
    "            \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_n_patches_overlap(img_np, true_vessel_np=False, indexes=None, selected_class=None, add_title='', m=5, alpha=0.5, save_dir='clusters_imgs'):\n",
    "    \n",
    "    save_dir = os.path.join(save_embeddings_path,save_dir)\n",
    "    mk_dir(save_dir)\n",
    "    plt.ioff()\n",
    "    n = len(indexes) if indexes is not None else 5\n",
    "    # m is the number of images to plot in each row (2m is the number of columns)\n",
    "    n_rows = int(np.ceil(n/m))\n",
    "    n_cols = m\n",
    "    \n",
    "    fig, ax = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 4*n_rows))\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    for i, index in enumerate(indexes):\n",
    "        ax[i].set_title(f'Overlay for Slice {index}')\n",
    "        masked_image = np.ma.masked_where(img_np[index,:,:] == 0, true_vessel_np[index,:,:])\n",
    "        # Overlay the red image on top of true_vessel_np[index,:,:]\n",
    "        ax[i].imshow(true_vessel_np[index,:,:], cmap='gray', interpolation='none')\n",
    "        ax[i].imshow(masked_image, cmap='Reds', alpha=alpha)\n",
    "        \n",
    "        ax[i].axis('off')\n",
    "    \n",
    "    try:\n",
    "        plt.tight_layout()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if add_title!='':\n",
    "        print(f\"Save Fig to {save_dir}\")\n",
    "        plt.savefig(os.path.join(save_dir,f'{add_title}_class_{selected_class}_patches.png'))\n",
    "        plt.close(fig)\n",
    "        \n",
    "    else:\n",
    "        print(\"Plotting..\")\n",
    "        plt.show()\n",
    "    plt.ion()\n",
    "\n",
    "    \n",
    "def plot_n_patches(img_np, true_vessel_np=False, indexes=None, selected_class=None, add_title='', m=5):\n",
    "    plt.ioff()\n",
    "    n = len(indexes) if indexes is not None else 5\n",
    "    if n > 1000:\n",
    "        print(f'WARNING: YOU ARE TRYING TO PLOT {n} images')\n",
    "    # m is the number of images to plot in each row (2m is the number of columns)\n",
    "    n_rows = int(np.ceil(n/m))\n",
    "    n_cols = 2*m\n",
    "    \n",
    "    fig, ax = plt.subplots(n_rows, n_cols, figsize=(3*n_cols, 3*n_rows))\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    for i, index in enumerate(indexes):\n",
    "        \n",
    "        if index == img_np.shape[0]:\n",
    "            index -= 1\n",
    "        if index == img_np.shape[0]-1:\n",
    "            index -= 2\n",
    "            \n",
    "        ax[2*i].set_title(f'Image Slice {index}')\n",
    "        ax[2*i].imshow(img_np[index,:,:], cmap='gray', vmin=0, vmax=1)\n",
    "        ax[2*i].axis('off')\n",
    "        print(f\"Shape: {img_np[index,:,:].shape}, Max: {img_np[index,:,:].max()}, Min: {img_np[index,:,:].min()}\")\n",
    "        if true_vessel_np is not False:\n",
    "            ax[2*i + 1].imshow(true_vessel_np[index,:,:], cmap='gray')\n",
    "            ax[2*i + 1].set_title(f'True Vessel Slice {index}')\n",
    "            \n",
    "        else:\n",
    "            ax[2*i + 1].set_title(f'Image Slice {index+1}')\n",
    "            ax[2*i + 1].imshow(img_np[index+1,:,:], cmap='gray', vmin=0, vmax=1)\n",
    "        \n",
    "        ax[2*i+1].axis('off')\n",
    "            \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if add_title!='':\n",
    "        print(\"Save Fig\")\n",
    "        plt.savefig(f'{add_title}_class_{selected_class}_patches.png')\n",
    "        plt.close(fig)\n",
    "        \n",
    "    else:\n",
    "        print(\"Plotting..\")\n",
    "        plt.show()\n",
    "    plt.ion()\n",
    "    \n",
    "def reshape_to_square(vector):\n",
    "    # Calculate the nearest square number greater than or equal to the length of the vector\n",
    "    n = int(np.ceil(np.sqrt(len(vector))))\n",
    "    \n",
    "    # Calculate the number of elements to pad with zeros\n",
    "    num_zeros = n*n - len(vector)\n",
    "    \n",
    "    # Pad the vector with zeros if necessary\n",
    "    vector_padded = np.pad(vector, (0, num_zeros), mode='constant')\n",
    "    \n",
    "    # Reshape the padded vector into a square matrix\n",
    "    square_matrix = vector_padded.reshape((n, n))\n",
    "    \n",
    "    return square_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_img_vessels_np2(dataset_img_dir):\n",
    "    print(f\"Extracting from {dataset_img_dir}\")\n",
    "    for i,img_name in enumerate(tqdm(os.listdir(dataset_img_dir))):\n",
    "        if '32_img.npy' not in img_name:\n",
    "            continue\n",
    "    # load png as a numpy\n",
    "        img_array = np.load(os.path.join(dataset_img_dir,img_name))\n",
    "        vess_array = np.load(os.path.join(dataset_img_dir,img_name).replace('img','label'))\n",
    "        if i==0:\n",
    "            img_list_np = img_array\n",
    "            vess_list_np = vess_array\n",
    "        else:\n",
    "            img_list_np = np.concatenate((img_list_np, img_array), axis=0)\n",
    "            vess_list_np = np.concatenate((vess_list_np, vess_array), axis=0)\n",
    "            \n",
    "    print(f\"Extracted {img_list_np.shape[0]} images and {vess_list_np.shape[0]} labels\")\n",
    "    \n",
    "    return img_list_np, vess_list_np\n",
    "\n",
    "def extract_empty_img_vessels(dataset_empty_img_dir):\n",
    "    print(f\"Extracting from {dataset_empty_img_dir}\")\n",
    "    for i,img_name in enumerate(tqdm(os.listdir(dataset_empty_img_dir))):\n",
    "        if '32_img.npy' not in img_name:\n",
    "            continue\n",
    "    # load png as a numpy\n",
    "        img_array = np.load(os.path.join(dataset_empty_img_dir,img_name))\n",
    "        if i==0:\n",
    "            img_list_np = img_array\n",
    "        else:\n",
    "            img_list_np = np.concatenate((img_list_np, img_array), axis=0)\n",
    "    print(f\"Extracted {img_list_np.shape[0]} images\")\n",
    "    \n",
    "    return img_list_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "def label_point(x, y, ids, ax):\n",
    "    \"\"\"Annotate points on plot with their IDs.\"\"\"\n",
    "    for i, txt in enumerate(ids):\n",
    "        ax.annotate(txt, (x[i], y[i]))\n",
    "\n",
    "def interactive_plot(x, y, ids=None, colors=None, action='click', img_list=None, emb_list=None, true_img_list=None ,zoom=False, filtered_ids=[]):\n",
    "    \"\"\"Identify the ID of a point by clicking on it.\"\"\"\n",
    "    if ids is None:\n",
    "        ids = [str(i) for i in range(len(x))]\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(12, 8)) if zoom else plt.subplots(1, 4, figsize=(16,4))\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    ax[1].axis('off')\n",
    "    ax[2].axis('off')\n",
    "    ax[3].axis('off')\n",
    "    \n",
    "    ax[0].scatter(x, y, s=1, c=colors, cmap='viridis') if colors is not None else ax[0].scatter(x, y, s=1 if zoom else 0.1)\n",
    "    # Set limit to the plot\n",
    "    if zoom:\n",
    "        ax[4].scatter(x, y, s=1, c=colors) if colors is not None else ax[4].scatter(x, y, s=1)\n",
    "        ax[4].set_xlim([-100, 100])\n",
    "        ax[4].set_ylim([-100, 100])\n",
    "        ax[5].axis('off')\n",
    "    # Set a threshold based on max values of x and y\n",
    "    threshold = max(max(x) - min(x), max(y) - min(y)) / 80\n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    #label_point(x, y, ids, ax[0])\n",
    "    tree = KDTree(np.column_stack((x, y)))\n",
    "    \n",
    "    def onclick(event):\n",
    "        \"\"\"Event handler for mouse click.\"\"\"\n",
    "        if event.inaxes == ax[0]:\n",
    "            dist, i = tree.query([event.xdata, event.ydata])\n",
    "            if dist < threshold:\n",
    "                ax[1].imshow(img_list[int(ids[i])], cmap='gray')\n",
    "                id_img_title = ids[i] if len(filtered_ids) == 0 else filtered_ids[i]\n",
    "                ax[1].set_title(f'Image {id_img_title} (color: {colors[i]})') if colors is not None else ax[1].set_title(f'Image {id_img_title}')\n",
    "                ax[2].imshow(reshape_to_square(emb_list[int(ids[i])]), cmap='gray')\n",
    "                ax[2].set_title(f'Embedding {id_img_title}')\n",
    "                ax[3].imshow(true_img_list[int(ids[i])], cmap='gray')\n",
    "                ax[3].set_title(f'True Image {id_img_title}')\n",
    "                \n",
    "                ax[1].axis('off')\n",
    "                ax[2].axis('off')\n",
    "                ax[3].axis('off')\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    if action == 'click':\n",
    "        fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "    elif action == 'hover':\n",
    "        fig.canvas.mpl_connect('motion_notify_event', onclick)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2_clusters(embeddings_tsne, cluster_labels, cluster_labels_2d):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], c=cluster_labels, s=1)\n",
    "    ax[0].set_title('Clustering Results (t-SNE embedding)')\n",
    "\n",
    "    ax[1].scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], c=cluster_labels_2d, s=1)\n",
    "    ax[1].set_title('Clustering Results (t-SNE embedding 2D)')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_class(embeddings, classes, class_label):\n",
    "    filtered_embeddings = []\n",
    "    filtered_classes = []\n",
    "    filtered_indices = []\n",
    "\n",
    "    for i, (embedding, class_value) in enumerate(zip(embeddings, classes)):\n",
    "        if str(class_value) == str(class_label):\n",
    "            #print(f\"IDX {i} -- Class value: {class_value} - Class label: {class_label}\")\n",
    "            filtered_embeddings.append(embedding)\n",
    "            filtered_classes.append(class_value)\n",
    "            filtered_indices.append(i)\n",
    "\n",
    "    filtered_embeddings = np.array(filtered_embeddings)\n",
    "    filtered_classes = np.array(filtered_classes)\n",
    "    filtered_indices = np.array(filtered_indices)\n",
    "    \n",
    "    return filtered_embeddings, filtered_classes, filtered_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_plot_filtered(x, y, ids=None, colors=None, action='click', selected_class=None, img_list=None, emb_list=None, true_img_list=None, do='plot'):\n",
    "    x, filtered_colors, indices = filter_class(x,colors,selected_class)\n",
    "    #assert set(filtered_colors) == {selected_class}\n",
    "    #print(f\"Number of elements in the class {selected_class}: {len(x)}\")\n",
    "    #print(f\"Indices of class {selected_class}: {indices}\")\n",
    "    y = y[indices]\n",
    "    img_list = img_list[indices]\n",
    "    emb_list = emb_list[indices]\n",
    "    true_img_list = true_img_list[indices]\n",
    "    \n",
    "    if do == 'plot':\n",
    "        print(\"Interactive plot...\")\n",
    "        interactive_plot(x, y, action=action, img_list=img_list, emb_list=emb_list, true_img_list=true_img_list, zoom=True, filtered_ids=indices)\n",
    "    \n",
    "    return img_list, emb_list, true_img_list, indices\n",
    "\n",
    "from matplotlib.widgets import Slider\n",
    "plt.ion() \n",
    "\n",
    "def plot_slices_with_cursor(img_np, mask_np, vessel_np, grid_np=None, cursor_position=10, indeces = []):\n",
    "    if grid_np is None:\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        def update(val):\n",
    "            slice_index = int(slider.val)\n",
    "            title = slice_index if len(indeces) == 0 else indeces[slice_index]\n",
    "            ax[0].imshow(img_np[slice_index], cmap='gray')\n",
    "            ax[0].set_title(f'Image Slice {title}')\n",
    "            ax[1].imshow(reshape_to_square(mask_np[slice_index]), cmap='gray')\n",
    "            ax[1].set_title(f'Mask Slice {title}')\n",
    "            ax[2].imshow(vessel_np[slice_index], cmap='gray')\n",
    "            ax[2].set_title(f'Embedding Slice {title}')\n",
    "            fig.canvas.draw_idle()\n",
    "\n",
    "        slider_ax = plt.axes([0.1, 0.01, 0.65, 0.03])\n",
    "        slider = Slider(slider_ax, 'Slice', 0, img_np.shape[0] - 1, valinit=cursor_position, valstep=1)\n",
    "        slider.on_changed(update)\n",
    "        plt.subplots_adjust(bottom=0.2)\n",
    "\n",
    "        # Initialize the plot\n",
    "        update(cursor_position)\n",
    "\n",
    "        slider_ax = plt.axes([0.1, 0.01, 0.65, 0.03])\n",
    "        slider = Slider(slider_ax, 'Slice', 0, img_np.shape[2] - 1, valinit=cursor_position, valstep=1)\n",
    "        slider.on_changed(update)\n",
    "        plt.subplots_adjust(bottom=0.2)\n",
    "\n",
    "        # Initialize the plot\n",
    "        update(cursor_position)\n",
    "        \n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_test_split_arrays(*arrays, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Split numpy arrays along the first axis into random train and test subsets.\n",
    "\n",
    "    Parameters:\n",
    "    *arrays : array-like\n",
    "        Arrays to be split. All arrays must have the same size along the first axis.\n",
    "    test_size : float or int, default=0.2\n",
    "        If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split.\n",
    "        If int, represents the absolute number of test samples.\n",
    "    random_state : int or RandomState instance, default=None\n",
    "        Controls the randomness of the training and testing indices.\n",
    "\n",
    "    Returns:\n",
    "    tuple of arrays\n",
    "        Tuple containing train-test split of input arrays.\n",
    "    \"\"\"\n",
    "    # Check if all arrays have the same size along the first axis\n",
    "    first_axis_lengths = [arr.shape[0] for arr in arrays]\n",
    "    if len(set(first_axis_lengths)) != 1:\n",
    "        raise ValueError(\"All input arrays must have the same size along the first axis.\")\n",
    "\n",
    "    assert first_axis_lengths[0] > 0, \"The size of the first axis should be greater than 0.\"\n",
    "    \n",
    "    # Determine the size of the test set\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = int(test_size * first_axis_lengths[0])\n",
    "    elif isinstance(test_size, int):\n",
    "        if test_size < 0 or test_size > first_axis_lengths[0]:\n",
    "            raise ValueError(\"test_size should be a positive integer less than or equal to the size of the first axis.\")\n",
    "    else:\n",
    "        raise ValueError(\"test_size should be either float or int.\")\n",
    "    \n",
    "    test_size = test_size if test_size > 0 else 1\n",
    "    \n",
    "    # Generate random indices for the test set\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    indices = np.arange(first_axis_lengths[0])\n",
    "    rng.shuffle(indices)\n",
    "    test_indices = indices[:test_size]\n",
    "    train_indices = indices[test_size:]\n",
    "\n",
    "    # Split arrays\n",
    "    train_arrays = tuple(arr[train_indices] for arr in arrays)\n",
    "    test_arrays = tuple(arr[test_indices] for arr in arrays)\n",
    "\n",
    "    return train_arrays, test_arrays\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/falcetta/0_PhD/sparse_var/vdisnet/'\n",
    "\n",
    "path_data = \"/data/falcetta/brain_data\"\n",
    "\n",
    "preprocessed_data_dir = os.path.join(path_data, \"IXIJ/processed/patches_preprocessed_with_empty\") \n",
    "    \n",
    "dataset_img_dir = os.path.join(path_data, \"IXIJ/processed/patches_preprocessed_with_empty/5_seg_true_patch_extraction\") \n",
    "\n",
    "dataset_name = 'IXI'\n",
    "save_embeddings_path = os.path.join(path_data, f\"embeddings_VDISNET\") \n",
    "\n",
    "take = 'all'\n",
    "\n",
    "mk_dir(save_embeddings_path)\n",
    "\n",
    "\n",
    "print(f\"Extracting images and vessels from {dataset_img_dir}\")\n",
    "print(f\"Saving outputs to {os.getcwd()}/{save_embeddings_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "\n",
    "    img_list_np, ves_list_np = extract_img_vessels_np2(dataset_img_dir)\n",
    "    \n",
    "    # Take just 1000 at random\n",
    "    if take == 'all':\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"Taking {take} at random\")\n",
    "        np.random.seed(0)\n",
    "        random_idx = np.random.choice(img_list_np.shape[0], take, replace=False)\n",
    "        \n",
    "        img_list_np = img_list_np[random_idx]\n",
    "        ves_list_np = ves_list_np[random_idx]\n",
    "\n",
    "    \n",
    "    \n",
    "    print(f\"Vessel list length: {len(ves_list_np)} - Img list length: {len(img_list_np)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    dataset_empty_img_dir = dataset_img_dir.replace('true','empty')\n",
    "\n",
    "    empty_img_list_np = extract_empty_img_vessels(dataset_empty_img_dir)\n",
    "    print(f'Empty img list shape: {empty_img_list_np.shape}')\n",
    "\n",
    "\n",
    "    if take == 'all':\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"Taking {take} empty images\")\n",
    "        np.random.seed(0)\n",
    "        #Take just 1000 at random\n",
    "        random_indices = np.random.choice(empty_img_list_np.shape[0], int(take), replace=False)\n",
    "        empty_img_list_np = empty_img_list_np[random_indices]\n",
    "        \n",
    "    empty_vess_list_np = np.zeros_like(empty_img_list_np)\n",
    "    print(f'Empty img list shape: {empty_img_list_np.shape}, Data list shape: {empty_vess_list_np.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    print(\"Plotting Empty (No Vessels) Patches\")\n",
    "    plot_10_patches(empty_vess_list_np, empty_img_list_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    print(\"Plotting Vessel Patches\")\n",
    "    print(f'img_list_np shape: {img_list_np.shape}')\n",
    "    print(f'data_list_np shape: {ves_list_np.shape}')\n",
    "\n",
    "    plot_10_patches(ves_list_np, img_list_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    np.save(os.path.join(save_embeddings_path, f'vess_list_{dataset_name}_{take}.npy'), ves_list_np)\n",
    "    np.save(os.path.join(save_embeddings_path, f'img_list_{dataset_name}_{take}.npy'), img_list_np)\n",
    "\n",
    "    np.save(os.path.join(save_embeddings_path, f'empty_vess_list_{dataset_name}_{take}.npy'), empty_vess_list_np)\n",
    "    np.save(os.path.join(save_embeddings_path, f'empty_img_list_{dataset_name}_{take}.npy'), empty_img_list_np)\n",
    "\n",
    "    print(f\"Data saved in {save_embeddings_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD SAVED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vess_list_np = np.load(os.path.join(save_embeddings_path, f'vess_list_{dataset_name}_{take}.npy'))\n",
    "img_list_np = np.load(os.path.join(save_embeddings_path, f'img_list_{dataset_name}_{take}.npy'))\n",
    "\n",
    "print(f\"Data loaded from {save_embeddings_path}\")\n",
    "print(f'data_list_np shape: {vess_list_np.shape}')\n",
    "print(f'img_list_np shape: {img_list_np.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_vess_list_np = np.load(os.path.join(save_embeddings_path, f'empty_vess_list_{dataset_name}_{take}.npy'))\n",
    "empty_img_list_np = np.load(os.path.join(save_embeddings_path, f'empty_img_list_{dataset_name}_{take}.npy'))\n",
    "\n",
    "print(f\"Data loaded from {save_embeddings_path}\")\n",
    "print(f'empty_data_list_np shape: {empty_vess_list_np.shape}')\n",
    "print(f'empty_img_list_np shape: {empty_img_list_np.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Create Dictionart Learning Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = os.path.join(root_dir, \"results\")\n",
    "OUTPUT_PATH = os.path.join(os.path.dirname(OUTPUT_PATH),\"\",os.path.basename(OUTPUT_PATH)) # Add \"CODE_DIMS\" if needed\n",
    "date = '2024-07-05'\n",
    "dtime = '15-57-09' # SDL\n",
    "#dtime = '16-11-06' # SDL-NL\n",
    "datetime = os.path.join(date, dtime)\n",
    "\n",
    "pretrained_path_enc = f'{OUTPUT_PATH}/{datetime}/checkpoints/ENC_best.pth'\n",
    "\n",
    "assert os.path.exists(pretrained_path_enc), f\"Pretrained encoder not found at {pretrained_path_enc}\"\n",
    "\n",
    "\n",
    "args = {\n",
    "    \"batch_size\": 200,\n",
    "    \"code_dim\": 256,\n",
    "    \"code_reg\": 1,\n",
    "    \"cuda\": True,\n",
    "    \"dataset\": \"VPATCHES\",\n",
    "    \"decoder\": \"linear_dictionary\",\n",
    "    \"encoder\": \"lista_encoder\",\n",
    "    \"epochs\": 1,\n",
    "    \"FISTA\": \"--FISTA\",\n",
    "    \"hidden_dim\": 0,\n",
    "    \"hinge_threshold\": 0.5,\n",
    "    \"im_size\": 32,\n",
    "    \"lrt_D\": 0.001,\n",
    "    \"lrt_E\": 0.0003,\n",
    "    \"lrt_Z\": 1,\n",
    "    \"n_steps_inf\": 200,\n",
    "    \"noise\": [1],\n",
    "    \"norm_decoder\": 1,\n",
    "    \"num_iter_LISTA\": 3,\n",
    "    \"num_workers\": 4,\n",
    "    \"outdir\": OUTPUT_PATH,\n",
    "    \"patch_size\": 0,\n",
    "    \"positive_ISTA\": \"--positive_ISTA\",\n",
    "    \"seed\": 31,\n",
    "    \"sparsity_reg\": 0.005,\n",
    "    \"stop_early\": 0.001,\n",
    "    \"pretrained_path_enc\": pretrained_path_enc,\n",
    "    \"use_Zs_enc_as_init\": \"use_Zs_enc_as_init\",\n",
    "    \"variance_reg\": 0,\n",
    "    \"weight_decay_D\": 0,\n",
    "    \"weight_decay_E\": 0,\n",
    "    \"weight_decay_E_bias\": 0,\n",
    "    \"weight_decay_D_bias\": 0\n",
    "}\n",
    "\n",
    "print(f\"Loading model from experiment {datetime} from {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotAccessibleDict:\n",
    "    def __init__(self, d):\n",
    "        self.__dict__['_dict'] = d\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return self._dict[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(f\"'DotAccessibleDict' object has no attribute '{name}'\")\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self._dict[name] = value\n",
    "        \n",
    "\n",
    "args = DotAccessibleDict(args)\n",
    "\n",
    "args.n_channels = 1\n",
    "args.train_decoder = False\n",
    "args.train_encoder = False\n",
    "args.code_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----- START -----\")\n",
    "# Get arguments\n",
    "print(\"--- Step 0: Get arguments\")\n",
    "# Create directory structure\n",
    "day = args.pretrained_path_enc.split('/')[-4]\n",
    "exp_time = args.pretrained_path_enc.split('/')[-3]\n",
    "\n",
    "outdir = os.path.join(save_embeddings_path, \"embeddings\" ,day, exp_time)\n",
    "mk_dir(outdir)\n",
    "\n",
    "print(f\"Embeddings will be saved in {outdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    # More logistics\n",
    "    device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "    # Random seed\n",
    "    print(\"--- Step 2: Set random seed\")\n",
    "    set_random_seed(args.seed, torch, np, random, args.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class MasksDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, masks_array, transform=None):\n",
    "        self.masks_array = masks_array\n",
    "        self.transform = transform\n",
    "        self.compute_metadata()\n",
    "         \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        # Select random index from the dataset\n",
    "        img0 = self.masks_array[index]\n",
    "        \n",
    "        # Convert numpy arrays to PIL Images\n",
    "        #img0 = Image.fromarray(img0)\n",
    "        \n",
    "        # Apply transformations if provided\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0.astype(np.float32))\n",
    "        \n",
    "        # Normalize images\n",
    "        img0 = (img0 - self.mean) / self.std\n",
    "        \n",
    "        # Standardize to 0-1\n",
    "        img0 = (img0 - img0.min()) / (img0.max() - img0.min())\n",
    "            \n",
    "        # Flag: 1 if same class, 0 if different class\n",
    "        \n",
    "        return img0\n",
    "    \n",
    "    def compute_metadata(self):\n",
    "        flattened_data = self.masks_array.reshape(self.masks_array.shape[0], -1)\n",
    "        means = np.mean(flattened_data, axis=0)\n",
    "        stds = np.std(flattened_data, axis=0)\n",
    "        \n",
    "        # compute the single mean and std\n",
    "        mean = np.mean(means)\n",
    "        std = np.mean(stds)\n",
    "        \n",
    "        #convert to pytorch\n",
    "        self.mean = torch.tensor(mean)\n",
    "        self.std = torch.tensor(std)\n",
    "        \n",
    "        print(f\"Mean: {self.mean} - Std: {self.std}\")\n",
    "        return self.mean, self.std\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.masks_array)\n",
    "    \n",
    "    def __shape__(self):\n",
    "        return self.masks_array.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    masks_dataset = MasksDataset(vess_list_np,transform=transforms.ToTensor())\n",
    "    print(f\"Dataset shape: {masks_dataset.__shape__()}\")\n",
    "    vessel_metadata = masks_dataset.compute_metadata()\n",
    "    \n",
    "    np.save(os.path.join(save_embeddings_path, f'VESSEL_metadata_{dataset_name}.npy'), vessel_metadata)\n",
    "    print(f\"Metadata saved in {save_embeddings_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_metadata = np.load(os.path.join(save_embeddings_path, f'VESSEL_metadata_{dataset_name}.npy'), allow_pickle=True)\n",
    "print(f\"Metadata loaded from {save_embeddings_path}: {vessel_metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    # Assuming you have a dataset called `masks_dataset`\n",
    "    test_batch_size = 1\n",
    "    test_shuffle = False\n",
    "\n",
    "    data_emb = DataLoader(masks_dataset, batch_size=test_batch_size, shuffle=test_shuffle)\n",
    "    args.n_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DECODER (For Dict Viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    # replace \n",
    "    args.pretrained_path_dec = args.pretrained_path_enc.replace('ENC_best','DEC_best')\n",
    "    print(f'Loading pre-trained enc from {args.pretrained_path_enc}')\n",
    "    print(f'Loading pre-trained dec from {args.pretrained_path_dec}')\n",
    "\n",
    "    # Decoder\n",
    "    decoder = getattr(import_module('models.{}'.format(args.decoder)), 'Decoder')(args).to(device)\n",
    "\n",
    "    # Load pretrained decoder, turn off gradients if not training it\n",
    "    print(\"--- Step 4: Load pretrained decoder, turn off gradients if not training it\")\n",
    "    decoder.load_pretrained(args.pretrained_path_dec, freeze=not(args.train_decoder))\n",
    "\n",
    "    # If not training the decoder, put it in eval() mode and remove gradient tracking\n",
    "    decoder.eval()\n",
    "    decoder.requires_grad_(False)\n",
    "        \n",
    "\n",
    "\n",
    "    n_samples = decoder.get_n_atoms()\n",
    "    cols1, cols2 = decoder.viz_columns2(n_samples, norm_each=True) #norm_each=True to normalize each column (max value to 1, min value to 0) (default: False)\n",
    "    #print(\"Saving decoder columns 1\")\n",
    "\n",
    "    save_img(cols1, os.path.join(outdir, \"complete_dict.png\"),\n",
    "                norm=False, n_rows=int(2 ** (np.log2(n_samples) // 2)))\n",
    "\n",
    "    if cols2 != 0:\n",
    "        save_img(cols2, os.path.join(outdir, \"complete_dict_hidden.png\"),\n",
    "                norm=False, n_rows=int(2 ** (np.log2(n_samples) // 2)))\n",
    "        \n",
    "        \n",
    "\n",
    "# TODO: YOU NEED TO CREATE A COPY OF MODELS INSIDE GET_EMBEDDING_DL TO ACCESS THE MODELS !!! (IS THERE A BETTER WAY?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder (For latent space extration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    # Logistics: data\n",
    "    print(f\"Number of channels: {args.n_channels}\")\n",
    "        \n",
    "    # Encoder\n",
    "    encoder = getattr(import_module('models.{}'.format(args.encoder)), 'Encoder')(args).to(device)\n",
    "    assert not(args.train_encoder) and len(args.pretrained_path_enc) > 0\n",
    "    # Load pretrained encoder, turn off gradients if not training it\n",
    "    print(\"--- Step 6: Load pretrained encoder, turn off gradients if not training it\")\n",
    "    encoder.load_pretrained(args.pretrained_path_enc, freeze=not(args.train_encoder))\n",
    "    # If not training the encoder, put it in eval() mode and remove gradient tracking\n",
    "    encoder.eval()\n",
    "    encoder.requires_grad_(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(X):\n",
    "    #datadir = '/home/falcetta/0_PhD/sparse_var/vdisnet/data/VESSEL' # NON MI PIACE MA PER ORA VA BENE\n",
    "    #mean, std = np.load(os.path.join(datadir, 'VESSEL_mean_std.npy'))\n",
    "    \n",
    "    mean, std = vessel_metadata\n",
    "    \n",
    "    return X * std + mean\n",
    "\n",
    "\n",
    "# TODO: WHERE I CREATE VESSEL_mean_std????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(target, pred, tar_sample_mean=None, tar_sample_std=None, pred_sample_mean=None, pred_sample_std=None,\n",
    "         R=1, dummy=1e-4, reduction='mean', binary_output=False):\n",
    "    \n",
    "    assert target.shape == pred.shape, f\"Target shape: {target.shape}, pred shape: {pred.shape}\"\n",
    "    \n",
    "        \n",
    "    #binarize pred using a threshold of 0.5\n",
    "    #if binary_output:\n",
    "        #target_mean_value = (target.max() - target.min()) / 2\n",
    "        #pred = torch.where(pred > target_mean_value, target.max(), target.min())\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        # Map inputs back to image space\n",
    "        if tar_sample_mean is not None:\n",
    "            target = (target * tar_sample_std) + tar_sample_mean\n",
    "            if pred_sample_mean is not None:\n",
    "                # Prediction comes from sample different from the target (e.g. in the case of denoising)\n",
    "                pred = (pred * pred_sample_std) + pred_sample_mean\n",
    "            else:\n",
    "                pred = (pred * tar_sample_std) + tar_sample_mean\n",
    "        target = inverse_transform(target)\n",
    "        pred = inverse_transform(pred)\n",
    "        # Compute the PSNR\n",
    "        dims = (1, 2, 3) if len(target.shape) == 4 else 1\n",
    "        mean_sq_err = ((target - pred)**2).mean(dims)\n",
    "        mean_sq_err = mean_sq_err + (mean_sq_err == 0).float() * dummy # if 0, fill with dummy -> PSNR of 40 by default\n",
    "        output = 10*torch.log10(R**2/mean_sq_err)\n",
    "        if reduction == 'mean':\n",
    "            return output.mean()\n",
    "        elif reduction == 'none':\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    # Training loop\n",
    "    print(\"--- Step 8: Embedding extraction\")\n",
    "    #create an empty np array to store the embeddings\n",
    "    if take == 'all':\n",
    "        take_num = len(data_emb)\n",
    "    embeddins_tot = np.empty((take_num, args.code_dim))\n",
    "    psnr_tot = np.empty((take_num))\n",
    "    for i, mask in enumerate(tqdm(data_emb)):\n",
    "        y = mask.to(device)\n",
    "        # Encoder predictions\n",
    "        Zs_enc = encoder(y) # Encoder input: y\n",
    "        # Append the embeddings to the array (along the first axis)\n",
    "        embeddins_tot[i] = Zs_enc.cpu().detach().numpy()\n",
    "\n",
    "        y_hat = decoder(Zs_enc)\n",
    "        #y_hat = binarize_prediction(y, y_hat) if args.binary_output else y_hat\n",
    "        psnr = PSNR(y, y_hat, None, None, binary_output=True)\n",
    "        psnr_tot[i] = psnr.item()\n",
    "\n",
    "    print(f\"embeddins_tot shape: {embeddins_tot.shape}\")\n",
    "    print(f\"psnr_tot shape: {psnr_tot.shape}\")\n",
    "    #save embeddings as a numpy array to\n",
    "    np.save(os.path.join(outdir, f\"embeddings_{dataset_name}_{take}.npy\"), embeddins_tot)\n",
    "    print(f\"Embeddings saved in {outdir}/embeddings_{dataset_name}_{take}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    # Print maximum\n",
    "    print(\"Maximum:\", np.max(psnr_tot))\n",
    "\n",
    "    # Print minimum\n",
    "    print(\"Minimum:\", np.min(psnr_tot))\n",
    "\n",
    "    # Print mean\n",
    "    print(\"Mean:\", np.mean(psnr_tot))\n",
    "\n",
    "    # Print standard deviation\n",
    "    print(\"Standard Deviation:\", np.std(psnr_tot))\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure()\n",
    "    # Plot histogram\n",
    "    plt.hist(psnr_tot, bins=10, alpha=0.5, color='blue', edgecolor='black')\n",
    "\n",
    "    # Add mean and standard deviation lines\n",
    "    plt.axvline(x=np.mean(psnr_tot), color='red', linestyle='dashed', linewidth=1)\n",
    "    plt.axvline(x=np.mean(psnr_tot) + np.std(psnr_tot), color='green', linestyle='dashed', linewidth=1)\n",
    "    plt.axvline(x=np.mean(psnr_tot) - np.std(psnr_tot), color='green', linestyle='dashed', linewidth=1)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('PSNR')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of PSNR')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(os.path.join(outdir, f\"embeddings_{dataset_name}_{take}.npy\"))\n",
    "print(f\"Embeddings loaded\")\n",
    "print(f\"embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not do_skip:\n",
    "\n",
    "    # Perform t-SNE clustering\n",
    "    #Peplexity 500\n",
    "    #early_exaggeration=40\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    embeddings_tsne = tsne.fit_transform(embeddings)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], s=1)\n",
    "    plt.title('Clustering Results (t-SNE embedding)')\n",
    "\n",
    "    # save the embeddings\n",
    "    np.save(os.path.join(outdir,f'embeddings_tsne_{dataset_name}_{take}.npy'), embeddings_tsne)\n",
    "    print(f\"TSNE embeddings saved in {os.path.join(outdir,f'embeddings_tsne_{take}.npy')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_tsne = np.load(os.path.join(outdir,f'embeddings_tsne_{dataset_name}_{take}.npy'))\n",
    "print(f\"TSNE embeddings loaded\")\n",
    "print(f\"TSNE embeddings shape: {embeddings_tsne.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_plot:\n",
    "    %matplotlib widget\n",
    "    interactive_plot(embeddings_tsne[:, 0], embeddings_tsne[:, 1], colors=None, action='click', img_list=vess_list_np, emb_list=embeddings, true_img_list=img_list_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_plot:\n",
    "    plot_n_patches_overlap(vess_list_np, img_list_np, indexes=[1625,24,25,26,23,46,1364, 1862], m=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## PLOT STATS (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_stats_plot:\n",
    "    # plot histogram of embeddings fraction of zeros\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(np.sum(embeddings == 0, axis=1) / embeddings.shape[1], bins=25)\n",
    "    plt.xlabel('Fraction of zeros')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "    max_frac_0s = np.max(np.sum(embeddings == 0, axis=1) / embeddings.shape[1])\n",
    "    min_frac_0s = np.min(np.sum(embeddings == 0, axis=1) / embeddings.shape[1])\n",
    "    mean_frac_0s = np.mean(np.sum(embeddings == 0, axis=1) / embeddings.shape[1])\n",
    "    std_frac_0s = np.std(np.sum(embeddings == 0, axis=1) / embeddings.shape[1])\n",
    "\n",
    "    print(f\"Max frac of zeros: {max_frac_0s} (index: {np.argmax(np.sum(embeddings == 0, axis=1) / embeddings.shape[1])}) (Number of non-zero elements: {np.sum(embeddings[np.argmax(np.sum(embeddings == 0, axis=1) / embeddings.shape[1])] != 0)}/{embeddings.shape[1]})\")\n",
    "    print(f\"Min frac of zeros: {min_frac_0s} (index: {np.argmin(np.sum(embeddings == 0, axis=1) / embeddings.shape[1])}) (Number of non-zero elements: {np.sum(embeddings[np.argmin(np.sum(embeddings == 0, axis=1) / embeddings.shape[1])] != 0)}/{embeddings.shape[1]})\")\n",
    "    print(f\"Mean frac of zeros: {mean_frac_0s}\")\n",
    "    print(f\"Standard deviation of frac of zeros: {std_frac_0s}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_stats_plot:\n",
    "    print(f\"Shape: {embeddings.shape}\")\n",
    "\n",
    "    #Max over the first dim\n",
    "    maxs = np.max(embeddings, axis=0)\n",
    "    mins = np.min(embeddings, axis=0)\n",
    "    print(f\"Min of min {np.min(mins)} - Max of mins {np.max(mins)}\")\n",
    "    print(f\"Min of max {np.min(maxs)} - Max of maxs {np.max(maxs)}\")\n",
    "\n",
    "    x = np.arange(0, maxs.size, 1)\n",
    "    y = maxs\n",
    "    # Plot the vector\n",
    "    fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "    ax[0].plot(x, y)\n",
    "    ax[0].set_xlabel('Dimension')\n",
    "    ax[0].set_ylabel('Max value')\n",
    "    ax[0].set_title('Max value per dimension')\n",
    "\n",
    "    #plot histogram of max values\n",
    "    ax[1].hist(maxs, bins=50)\n",
    "    ax[1].set_xlabel('Max value')\n",
    "    ax[1].set_ylabel('Count')\n",
    "    ax[1].set_title('Histogram of max values')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_stats_plot:\n",
    "    # plot histogram of embeddings over the second dimension\n",
    "    embedding1 = embeddings[:,1]\n",
    "    print(f\"Frac of zeros (embedding 1): {np.sum(embedding1 == 0) / embedding1.size}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(embedding1, bins=50)\n",
    "    plt.xlabel('Atom Value')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "    #same but remove the zeros\n",
    "    embedding1_wo_0s = embedding1[embedding1 != 0]\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(embedding1_wo_0s, bins=10)\n",
    "    plt.xlabel('Atom Value')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Min of embedding 1 w/o 0s: {np.min(embedding1_wo_0s)} - Max of embedding 1 w/o 0s: {np.max(embedding1_wo_0s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_stats_plot:\n",
    "    # plot the index of the elements that are not 0\n",
    "    non_zero_num = []\n",
    "    for i in range(embeddings.shape[0]):\n",
    "        non_zero_idx = np.where(embeddings[i] != 0)\n",
    "        non_zero_num.append(len(non_zero_idx[0]))\n",
    "        print(f\"Non zero idx ({i} (Len: {len(non_zero_idx[0]):3d}): {non_zero_idx[0]}\")\n",
    "\n",
    "    print(f\"Max non zero elements: {np.max(non_zero_num)} (index: {np.argmax(non_zero_num)})\")\n",
    "    print(f\"Min non zero elements: {np.min(non_zero_num)} (index: {np.argmin(non_zero_num)})\")\n",
    "\n",
    "    #plot mean non zero elements\n",
    "    mean_non_zero = np.mean(non_zero_num)\n",
    "    print(f\"Mean non zero elements: {mean_non_zero}\")\n",
    "\n",
    "    median_non_zero = np.median(non_zero_num)\n",
    "    print(f\"Median non zero elements: {median_non_zero}\")\n",
    "    \n",
    "    std_non_zero = np.std(non_zero_num)\n",
    "    print(f\"Std non zero elements: {std_non_zero}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_stats_plot:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(non_zero_num, bins=25)\n",
    "    plt.xlabel('Number of non zero elements')\n",
    "    plt.ylabel('Count')\n",
    "    plt.axvline(mean_non_zero, color='r', linestyle='dashed', linewidth=1)\n",
    "    plt.axvline(median_non_zero, color='orange', linestyle='dashed', linewidth=1)\n",
    "    plt.axvline(mean_non_zero + std_non_zero, color='g', linestyle='dashed', linewidth=1)\n",
    "    plt.axvline(mean_non_zero - std_non_zero, color='g', linestyle='dashed', linewidth=1)\n",
    "    plt.legend(['Mean', 'Median'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_stats_plot:\n",
    "    binary_embeddings = np.where(embeddings != 0, 1, 0)\n",
    "\n",
    "    #Sum over the column\n",
    "    def plot_activation_map(embedding_np, mode = 'count'):\n",
    "        sum_col = np.sum(embedding_np, axis=0)\n",
    "\n",
    "        #for i, s in enumerate(sum_col):\n",
    "        #    print(f\"Atom {i} is activated {s} times ({s / embedding_np.shape[0] * 100:.2f}% of the times)\")\n",
    "        if mode == 'count':    \n",
    "            print(f\"\\nMax activated atom: {np.max(sum_col)} times (index: {np.argmax(sum_col)})\")\n",
    "            print(f\"Min activated atom: {np.min(sum_col)} times (index: {np.argmin(sum_col)})\")\n",
    "        elif mode == 'sum':\n",
    "            print(f\"\\nMax activated atom: value {np.max(sum_col)} (index: {np.argmax(sum_col)})\")\n",
    "            print(f\"Min activated atom: value {np.min(sum_col)} (index: {np.argmin(sum_col)})\")\n",
    "        \n",
    "        # Plot a map of the activations (the more red the more activated)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(reshape_to_square(sum_col), cmap='YlGn', interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "        plt.title(f'Activation map of the atoms ({mode.upper()})')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    plot_activation_map(binary_embeddings) # COUNT\n",
    "    plot_activation_map(embeddings, 'sum') # COUNT + WEIGTHS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-MEANS with TSNE (Skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "if not do_skip:\n",
    "    # Create a KMeans object with the desired number of clusters\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')\n",
    "\n",
    "    # Fit the KMeans model to the embeddings\n",
    "    kmeans.fit(embeddings_tsne)\n",
    "\n",
    "    # Get the cluster labels for each data point\n",
    "    cluster_labels_2d = kmeans.labels_\n",
    "    print(f\"Classes: {set(cluster_labels_2d)}\")\n",
    "    np.save(os.path.join(outdir,f'cluster_labels_2d_{dataset_name}_{take}.npy'), cluster_labels_2d)\n",
    "\n",
    "\n",
    "    # Plot histogram of cluster labels\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(cluster_labels_2d, bins=n_clusters)\n",
    "    plt.xlabel('Cluster Label')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Histogram of Cluster Labels')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels_2d = np.load(os.path.join(outdir,f'cluster_labels_2d_{dataset_name}_{take}.npy'))\n",
    "print(f\"Loading cluster labels from {os.path.join(outdir,f'cluster_labels_2d_{dataset_name}_{take}.npy')}\")\n",
    "print(f\"Cluster labels loaded\")\n",
    "print(f\"Cluster labels shape: {cluster_labels_2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_plot:\n",
    "    interactive_plot(embeddings_tsne[:, 0], embeddings_tsne[:, 1], colors=cluster_labels_2d, action='click', img_list=vess_list_np, emb_list=embeddings, true_img_list=img_list_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-MEANS with embedding code (Skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "if not do_skip:\n",
    "    # Create a KMeans object with the desired number of clusters\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')\n",
    "\n",
    "    # Fit the KMeans model to the embeddings\n",
    "    kmeans.fit(embeddings)\n",
    "\n",
    "    # Get the cluster labels for each data point\n",
    "    cluster_labels = kmeans.labels_\n",
    "    print(f\"Classes: {set(cluster_labels)}\")\n",
    "    np.save(os.path.join(outdir,f'cluster_labels_{dataset_name}_{take}.npy'), cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = np.load(os.path.join(outdir,f'cluster_labels_{dataset_name}_{take}.npy'))\n",
    "print(f\"Cluster labels loaded\")\n",
    "print(f\"Cluster labels shape: {cluster_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_plot:\n",
    "    interactive_plot(embeddings_tsne[:, 0], embeddings_tsne[:, 1], colors=cluster_labels, action='click', img_list=vess_list_np, emb_list=embeddings, true_img_list=img_list_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_plot:\n",
    "    plot_2_clusters(embeddings_tsne, cluster_labels, cluster_labels_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Optional to save clusters imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "if do_optional_plots:\n",
    "    pick_colors = 'ND' # '2D' or 'ND\n",
    "    add_title = f\"{pick_colors}_{take}\"\n",
    "    # select 10 values at random between 0 and n_cluster\n",
    "    selected_classes = np.random.choice(n_clusters, 1, replace=False)\n",
    "    #selected_classes = range(10)\n",
    "    #selected_classes = range(n_clusters)\n",
    "\n",
    "    colors = cluster_labels_2d if pick_colors == '2D' else cluster_labels\n",
    "    do = \"filter\" # \"filter\" or \"plot\"\n",
    "    n_columns = 10\n",
    "\n",
    "    print(f\"Interactive plot filtered over 1 class ({pick_colors} Embedding)\")\n",
    "    print(f\"Saving image of clusters {selected_classes}\")\n",
    "    for selected_class in tqdm(selected_classes):\n",
    "        #print(f\"Selected class: {selected_class}\")\n",
    "        plt.close('all')\n",
    "        f_img_list, f_emb_list, f_true_img_list, f_indices = interactive_plot_filtered(embeddings_tsne[:, 0], embeddings_tsne[:, 1], colors=colors, action='click', selected_class=selected_class, img_list=vess_list_np, emb_list=embeddings, true_img_list=img_list_np, do=do)\n",
    "        plot_n_patches_overlap(vess_list_np, img_list_np, indexes=f_indices, selected_class=selected_class, add_title=add_title, m=n_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_optional_plots:\n",
    "    interactive_plot_filtered(embeddings_tsne[:, 0], embeddings_tsne[:, 1], colors=colors, action='click', selected_class=12, img_list=vess_list_np, emb_list=embeddings, true_img_list=img_list_np, do='plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_optional_plots:    \n",
    "    interactive_plot(embeddings_tsne[:, 0], embeddings_tsne[:, 1], colors=cluster_labels, action='click', img_list=vess_list_np, emb_list=embeddings, true_img_list=img_list_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIAMESE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_resnet = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Img shape: {img_list_np.shape}\")\n",
    "print(f\"Data shape: {vess_list_np.shape}\\n\")\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"TSNE embeddings shape: {embeddings_tsne.shape}\\n\")\n",
    "\n",
    "print(f\"Cluster labels shape: {cluster_labels.shape}\")\n",
    "print(f\"Cluster labels 2D shape: {cluster_labels_2d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD EMPTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Empty img list shape: {empty_img_list_np.shape}\")\n",
    "print(f\"Empty data list shape: {empty_vess_list_np.shape}\")\n",
    "\n",
    "max_cluster_value = np.max(cluster_labels)\n",
    "max_cluster_value_2d = np.max(cluster_labels_2d)\n",
    "\n",
    "print(f\"Max cluster value: {max_cluster_value}\")\n",
    "print(f\"Max cluster value 2D: {max_cluster_value_2d}\")\n",
    "\n",
    "# Create an array that has as shape the shape of empty_img_list_np[0] and fill it with the max value of the cluster labels +1\n",
    "empty_cluster_labels = np.full((empty_img_list_np.shape[0],), max_cluster_value+1)\n",
    "empty_cluster_labels_2d = np.full((empty_img_list_np.shape[0],), max_cluster_value_2d+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_np_tot = np.concatenate((img_list_np, empty_img_list_np), axis=0)\n",
    "vess_list_np_tot = np.concatenate((vess_list_np, empty_vess_list_np), axis=0)\n",
    "\n",
    "print(f\"Img shape: {img_list_np_tot.shape}\")\n",
    "print(f\"Data shape: {vess_list_np_tot.shape}\\n\")\n",
    "\n",
    "cluster_labels_tot = np.concatenate((cluster_labels, empty_cluster_labels), axis=0)\n",
    "cluster_labels_2d_tot = np.concatenate((cluster_labels_2d, empty_cluster_labels_2d), axis=0)\n",
    "\n",
    "print(f\"Cluster labels shape: {cluster_labels_tot.shape}\")\n",
    "print(f\"Cluster labels 2D shape: {cluster_labels_2d_tot.shape}\")\n",
    "\n",
    "print(f\"Unique cluster labels {len(set(cluster_labels_tot))} ==> {set(cluster_labels_tot)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwrite the variables !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_np = img_list_np_tot\n",
    "vess_list_np = vess_list_np_tot\n",
    "\n",
    "\n",
    "print(f\"Empty img list shape: {img_list_np.shape}\")\n",
    "print(f\"Empty data list shape: {vess_list_np.shape}\")\n",
    "\n",
    "cluster_labels = cluster_labels_tot\n",
    "cluster_labels_2d = cluster_labels_2d_tot\n",
    "\n",
    "print(f\"Max cluster value: {np.max(cluster_labels)}\")\n",
    "print(f\"Max cluster value 2D: {np.max(cluster_labels_2d)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTINUE SIAMESE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def imshow(img,text=None,should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss, title=''):\n",
    "    plt.figure()\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.title(f\"{title} Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import random\n",
    "\n",
    "class SiameseNetworkDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, images_array, labels_array, transform=None, test_mode=False, mode='double', metadata=None):\n",
    "        self.images_array = images_array\n",
    "        self.labels_array = labels_array\n",
    "        self.transform = transform\n",
    "        \n",
    "        if metadata is None:\n",
    "            self.compute_metadata()\n",
    "        else:\n",
    "            self.mean, self.std = metadata\n",
    "            self.compute_test_metadata()\n",
    "            \n",
    "        self.test_mode = test_mode\n",
    "        self.mode=mode\n",
    "         \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        # Select random index from the dataset\n",
    "        if self.mode == 'single':\n",
    "            idx_0 = int(index)\n",
    "            img0, label0 = self.images_array[idx_0], self.labels_array[idx_0]\n",
    "            # Convert numpy arrays to PIL Images\n",
    "            img0 = Image.fromarray(img0)\n",
    "            # Apply transformations if provided\n",
    "            if self.transform is not None:\n",
    "                img0 = self.transform(img0)\n",
    "            # Normalize images\n",
    "            img0 = (img0 - self.mean) / self.std    \n",
    "            # Standardize to 0-1\n",
    "            img0 = (img0 - img0.min()) / (img0.max() - img0.min())\n",
    "                \n",
    "            return img0\n",
    "        \n",
    "        else:\n",
    "            idx_0 = int(index)\n",
    "            img0, label0 = self.images_array[idx_0], self.labels_array[idx_0]\n",
    "            \n",
    "            # Determine whether to select a sample from the same class or different class\n",
    "            should_get_same_class = random.randint(0, 1) \n",
    "            if should_get_same_class:\n",
    "                while True:\n",
    "                    idx_1 = random.randint(0, len(self.images_array) - 1)\n",
    "                    img1, label1 = self.images_array[idx_1], self.labels_array[idx_1]\n",
    "                    if label0 == label1:\n",
    "                        break\n",
    "            else:\n",
    "                while True:\n",
    "                    idx_1 = random.randint(0, len(self.images_array) - 1)\n",
    "                    img1, label1 = self.images_array[idx_1], self.labels_array[idx_1]\n",
    "                    if label0 != label1:\n",
    "                        break\n",
    "    \n",
    "            if self.test_mode:\n",
    "                print(f\"Testing {idx_0} (class {label0}) against {idx_1} (class {label1})\")\n",
    "                \n",
    "            # Convert numpy arrays to PIL Images\n",
    "            img0 = Image.fromarray(img0)\n",
    "            img1 = Image.fromarray(img1)\n",
    "    \n",
    "            # Apply transformations if provided\n",
    "            if self.transform is not None:\n",
    "                img0 = self.transform(img0)\n",
    "                img1 = self.transform(img1)\n",
    "            \n",
    "            # Normalize images\n",
    "            img0 = (img0 - self.mean) / self.std\n",
    "            img1 = (img1 - self.mean) / self.std\n",
    "            \n",
    "            # Standardize to 0-1\n",
    "            img0 = (img0 - img0.min()) / (img0.max() - img0.min())\n",
    "            img1 = (img1 - img1.min()) / (img1.max() - img1.min())\n",
    "                \n",
    "            # Flag: 1 if same class, 0 if different class\n",
    "            flag = torch.from_numpy(np.array([int(label1 != label0)], dtype=np.float32))\n",
    "            \n",
    "            return img0, img1, flag\n",
    "        \n",
    "    def compute_metadata(self):\n",
    "        flattened_data = self.images_array.reshape(self.images_array.shape[0], -1)\n",
    "        means = np.mean(flattened_data, axis=0)\n",
    "        stds = np.std(flattened_data, axis=0)\n",
    "        \n",
    "        # compute the single mean and std\n",
    "        mean = np.mean(means)\n",
    "        std = np.mean(stds)\n",
    "        \n",
    "        #convert to pytorch\n",
    "        self.mean = torch.tensor(mean)\n",
    "        self.std = torch.tensor(std)\n",
    "        \n",
    "        print(f\"Mean: {self.mean} - Std: {self.std}\")\n",
    "    \n",
    "    def compute_test_metadata(self):\n",
    "        flattened_data = self.images_array.reshape(self.images_array.shape[0], -1)\n",
    "        means = np.mean(flattened_data, axis=0)\n",
    "        stds = np.std(flattened_data, axis=0)\n",
    "        \n",
    "        # compute the single mean and std\n",
    "        mean = np.mean(means)\n",
    "        std = np.mean(stds)\n",
    "        \n",
    "        #convert to pytorch\n",
    "        self.test_metadata = (torch.tensor(mean), torch.tensor(std))\n",
    "        \n",
    "        print(f\"Test Mean: {self.test_metadata[0]} - Test Std: {self.test_metadata[1]}\")\n",
    "\n",
    "    def get_metadata(self):\n",
    "        return self.mean, self.std\n",
    "    \n",
    "    def get_test_metadata(self):\n",
    "        return self.test_metadata\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Img shape: {img_list_np.shape}\")\n",
    "print(f\"Data shape: {vess_list_np.shape}\\n\")\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"TSNE embeddings shape: {embeddings_tsne.shape}\\n\")\n",
    "\n",
    "print(f\"Cluster labels shape: {cluster_labels.shape}\")\n",
    "print(f\"Cluster labels 2D shape: {cluster_labels_2d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    train_arrays, val_arrays = train_test_split_arrays(img_list_np, vess_list_np, cluster_labels, test_size=0.15, random_state=42)\n",
    "\n",
    "    X_train, X_train_mask, y_train = train_arrays\n",
    "    X_val, X_val_mask, y_val = val_arrays\n",
    "\n",
    "    # TODO: this test_arrays should be another dataset\n",
    "    #train_arrays, test_arrays = train_test_split_arrays(X_train, X_train_mask, y_train, test_size=0.15, random_state=42)\n",
    "\n",
    "    #X_train, X_train_mask, y_train = train_arrays\n",
    "    #X_test, X_test_mask, y_test = test_arrays\n",
    "\n",
    "\n",
    "\n",
    "    # Print the shapes of the train and test sets\n",
    "    print(\"Train set shape:\", X_train.shape)\n",
    "    print(\"Val set shape:\", X_val.shape)\n",
    "    #print(\"Test set shape:\", X_test.shape)\n",
    "\n",
    "    print(y_train.shape,y_val.shape)\n",
    "\n",
    "    np.save(os.path.join(save_embeddings_path,f'X_train_{dataset_name}_{take}.npy'), X_train)\n",
    "    np.save(os.path.join(save_embeddings_path,f'X_val_{dataset_name}_{take}.npy'), X_val)\n",
    "\n",
    "    np.save(os.path.join(save_embeddings_path,f'y_train_{dataset_name}_{take}.npy'), y_train)\n",
    "    np.save(os.path.join(save_embeddings_path,f'y_val_{dataset_name}_{take}.npy'), y_val)\n",
    "\n",
    "    np.save(os.path.join(save_embeddings_path,f'X_train_mask_{dataset_name}_{take}.npy'), X_train_mask)\n",
    "    np.save(os.path.join(save_embeddings_path,f'X_val_mask_{dataset_name}_{take}.npy'), X_val_mask)\n",
    "else:\n",
    "    print(\"Skipping train-test split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CAS Dataset !!! (After calling patches_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close all the plots\n",
    "plt.close('all')\n",
    "dataset_test_name = 'CAS'\n",
    "\n",
    "if not do_skip:\n",
    "    testset_img_dir = '/data/falcetta/brain_data/CASJ/preprocessed/patches_preprocessed_with_empty/5_seg_true_patch_extraction'\n",
    "    img_list_np_test , data_list_np_test = extract_img_vessels_np2(testset_img_dir)\n",
    "    X_test, X_test_mask = img_list_np_test , data_list_np_test\n",
    "    y_test = np.zeros(X_test.shape[0])\n",
    "    print(\"Test set shape:\", X_test.shape)\n",
    "    print(\"Test set mask shape:\", X_test_mask.shape)\n",
    "    print(\"Test set labels shape:\", y_test.shape)\n",
    "\n",
    "    plot_10_patches(X_test_mask, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    np.save(os.path.join(save_embeddings_path,f'X_test_{dataset_test_name}_{take}.npy'), X_test)\n",
    "    np.save(os.path.join(save_embeddings_path,f'y_test_{dataset_test_name}_{take}.npy'), y_test)\n",
    "    np.save(os.path.join(save_embeddings_path,f'X_test_mask_{dataset_test_name}_{take}.npy'), X_test_mask)\n",
    "    print(f\"Test set saved in {save_embeddings_path} ({take})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    empty_img_list_np_test = extract_empty_img_vessels(testset_img_dir.replace('true','empty'))\n",
    "    empty_data_list_np_test = np.zeros_like(empty_img_list_np_test)\n",
    "    print(f'Empty img list shape: {empty_img_list_np_test.shape}, Data list shape: {empty_data_list_np_test.shape}')\n",
    "\n",
    "    X_test_empty, X_test_mask_empty = empty_img_list_np_test , empty_data_list_np_test\n",
    "    y_test_empty = np.zeros(X_test_empty.shape[0])\n",
    "\n",
    "    print(\"Test empty set shape:\", X_test_empty.shape)\n",
    "    print(\"Test empty set mask shape:\", X_test_mask_empty.shape)\n",
    "    print(\"Test empty set labels shape:\", y_test_empty.shape)\n",
    "\n",
    "    plot_10_patches(X_test_mask_empty, X_test_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    np.save(os.path.join(save_embeddings_path,f'X_test_empty_{dataset_test_name}_{take}.npy'), X_test_empty)\n",
    "    np.save(os.path.join(save_embeddings_path,f'y_test_empty_{dataset_test_name}_{take}.npy'), y_test_empty)\n",
    "    np.save(os.path.join(save_embeddings_path,f'X_test_empty_mask_{dataset_test_name}_{take}.npy'), X_test_mask_empty)\n",
    "    print(f\"Empty set saved in {save_embeddings_path} ({take})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(save_embeddings_path,f'X_train_{dataset_name}_{take}.npy'))\n",
    "X_train_mask = np.load(os.path.join(save_embeddings_path,f'X_train_mask_{dataset_name}_{take}.npy'))\n",
    "y_train = np.load(os.path.join(save_embeddings_path,f'y_train_{dataset_name}_{take}.npy'))\n",
    "\n",
    "X_val = np.load(os.path.join(save_embeddings_path,f'X_val_{dataset_name}_{take}.npy'))\n",
    "X_val_mask = np.load(os.path.join(save_embeddings_path,f'X_val_mask_{dataset_name}_{take}.npy'))\n",
    "y_val = np.load(os.path.join(save_embeddings_path,f'y_val_{dataset_name}_{take}.npy'))\n",
    "\n",
    "X_test = np.load(os.path.join(save_embeddings_path,f'X_test_{dataset_test_name}_{take}.npy'))\n",
    "X_test_mask = np.load(os.path.join(save_embeddings_path,f'X_test_mask_{dataset_test_name}_{take}.npy'))\n",
    "y_test = np.load(os.path.join(save_embeddings_path,f'y_test_{dataset_test_name}_{take}.npy'))\n",
    "\n",
    "X_test_empty = np.load(os.path.join(save_embeddings_path,f'X_test_empty_{dataset_test_name}_{take}.npy'))\n",
    "X_test_mask_empty = np.load(os.path.join(save_embeddings_path,f'X_test_empty_mask_{dataset_test_name}_{take}.npy'))\n",
    "y_test_empty = np.load(os.path.join(save_embeddings_path,f'y_test_empty_{dataset_test_name}_{take}.npy'))\n",
    "\n",
    "\n",
    "print(f\"Train Data loaded (IXI)\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_train_mask shape: {X_train_mask.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\\n\")\n",
    "\n",
    "print(f\"Val Data loaded (IXI)\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"X_val_mask shape: {X_val_mask.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\\n\")\n",
    "\n",
    "print(f\"Test Data loaded (CAS)\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"X_test_mask shape: {X_test_mask.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\\n\")\n",
    "\n",
    "print(f\"X_test_empty shape: {X_test_empty.shape}\")\n",
    "print(f\"X_test_empty_mask shape: {X_test_mask_empty.shape}\")\n",
    "print(f\"y_test_empty shape: {y_test_empty.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tot = np.concatenate((X_test, X_test_empty), axis=0)\n",
    "X_test_mask_tot = np.concatenate((X_test_mask, X_test_mask_empty), axis=0)\n",
    "y_test_tot = np.concatenate((y_test, y_test_empty), axis=0)\n",
    "\n",
    "print(f\"X_test_tot shape: {X_test_tot.shape}\")\n",
    "print(f\"X_test_mask_tot shape: {X_test_mask_tot.shape}\")\n",
    "print(f\"y_test_tot shape: {y_test_tot.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test_tot\n",
    "X_test_mask = X_test_mask_tot\n",
    "y_test = y_test_tot\n",
    "\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"X_test_mask shape: {X_test_mask.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_10_patches(X_test_mask, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "if not do_skip:\n",
    "    siamese_dataset = SiameseNetworkDataset(images_array=X_train,\n",
    "                                            labels_array=y_train,\n",
    "                                            transform=transforms.ToTensor(),)\n",
    "\n",
    "    metadata = siamese_dataset.get_metadata()\n",
    "    np.save(os.path.join(save_embeddings_path,f'metadata_{dataset_name}_{take}.npy'), metadata)\n",
    "\n",
    "    siamese_val_dataset = SiameseNetworkDataset(images_array=X_val,\n",
    "                                                labels_array=y_val,\n",
    "                                                transform=transforms.ToTensor(),\n",
    "                                                metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = np.load(os.path.join(save_embeddings_path,f'metadata_{dataset_name}_{take}.npy'))\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "if not do_skip:\n",
    "    vis_dataloader = DataLoader(siamese_dataset,\n",
    "                            shuffle=True,\n",
    "                            num_workers=0,\n",
    "                            batch_size=1)\n",
    "\n",
    "    plot_same = True\n",
    "    plot_diff = True\n",
    "\n",
    "    print(f\"Plotting examples of the same (0) and different (1) clusters\")\n",
    "\n",
    "    plt.close('all')\n",
    "    plt.figure()\n",
    "    for example_batch in vis_dataloader:\n",
    "        if int(example_batch[2]) == 0 and plot_same:\n",
    "            concatenated = torch.cat((example_batch[0],example_batch[1]),0) # 8,1,100,100\n",
    "            print(f\"Flag: {int(example_batch[2])}\")\n",
    "            imshow(torchvision.utils.make_grid(concatenated))\n",
    "            plot_same = False\n",
    "        if int(example_batch[2]) == 1 and plot_diff:\n",
    "            concatenated = torch.cat((example_batch[0],example_batch[1]),0) # 8,1,100,100\n",
    "            print(f\"Flag: {int(example_batch[2])}\")\n",
    "            imshow(torchvision.utils.make_grid(concatenated))\n",
    "            plot_diff = False\n",
    "        if not plot_same and not plot_diff:\n",
    "            break   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ORIGINAL\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, embedding_size=128, pretrained = False):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(1, 4, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Dropout2d(p=0.3),  # Add dropout\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(4, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout2d(p=0.3),  # Add dropout\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(8, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout2d(p=0.3)  # Add dropout\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(8*32*32, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(500),  # Batch normalization for fully connected layer\n",
    "\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(500),  # Batch normalization for fully connected layer\n",
    "\n",
    "            nn.Linear(500, embedding_size)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2, mode='double'):\n",
    "        output1 = self.forward_once(input1)\n",
    "        if mode == 'single':\n",
    "            return output1\n",
    "        output2 = self.forward_once(input2)\n",
    "        \n",
    "        return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WITH RESNET\n",
    "if use_resnet:\n",
    "    print(\"USE RESNET\")\n",
    "    import torch.nn as nn\n",
    "\n",
    "    import torch.nn as nn\n",
    "    import torchvision.models as models\n",
    "\n",
    "    class SiameseNetwork(nn.Module):\n",
    "        def __init__(self, embedding_size=128, pretrained = False):\n",
    "            super(SiameseNetwork, self).__init__()\n",
    "            \n",
    "            # Load pre-trained ResNet-50\n",
    "            resnet = models.resnet50(pretrained=pretrained)\n",
    "            \n",
    "            # Modify the first convolutional layer to accept 1 input channel\n",
    "            self.resnet_features = nn.Sequential(\n",
    "                nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "                *list(resnet.children())[1:-2]\n",
    "            )\n",
    "            # Remove the last fully connected layer of ResNet-50\n",
    "            #self.resnet_features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "            # Define fully connected layers for embedding\n",
    "            self.fc1 = nn.Sequential(\n",
    "                nn.Linear(resnet.fc.in_features, 500),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm1d(500),\n",
    "                nn.Linear(500, 500),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm1d(500),\n",
    "                nn.Linear(500, embedding_size)\n",
    "            )\n",
    "\n",
    "        def forward_once(self, x):\n",
    "            # Extract features using ResNet\n",
    "            features = self.resnet_features(x)\n",
    "            features = features.view(features.size(0), -1)\n",
    "            output = self.fc1(features)\n",
    "            return output\n",
    "\n",
    "        def forward(self, input1, input2, mode='double'):\n",
    "            output1 = self.forward_once(input1)\n",
    "            if mode == 'single':\n",
    "                return output1\n",
    "            output2 = self.forward_once(input2)\n",
    "            return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.loss_accumulator = 0.0\n",
    "        self.num_samples = 0\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)\n",
    "        loss_contrastive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) + (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        \n",
    "        self.loss_accumulator += loss_contrastive.item()\n",
    "        self.num_samples += 1\n",
    "        return loss_contrastive\n",
    "\n",
    "    def get_accumulated_loss(self):\n",
    "        return self.loss_accumulator\n",
    "\n",
    "    def get_mean_loss(self):\n",
    "        self.mean_loss = self.loss_accumulator / self.num_samples\n",
    "        self.reset()\n",
    "        return self.mean_loss\n",
    "        \n",
    "    def reset(self):\n",
    "        self.loss_accumulator = 0.0\n",
    "        self.num_samples = 0\n",
    "\n",
    "\"\"\"\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin=.5, **kwargs):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        # self.metric = metric\n",
    "        self.distance = torch.nn.PairwiseDistance(p=2)\n",
    "\n",
    "    def forward(self, out0, out1, label):\n",
    "        gt = label.float()\n",
    "        D = self.distance(out0, out1).float().squeeze()\n",
    "        loss = gt * 0.5 * torch.pow(D, 2) + (1 - gt) * 0.5 * torch.pow(torch.clamp(self.margin - D, min=0.0), 2)\n",
    "        return loss\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    train_dataloader = DataLoader(siamese_dataset,\n",
    "                            shuffle=True,\n",
    "                            num_workers=8,\n",
    "                            batch_size=128)\n",
    "\n",
    "    val_dataloader = DataLoader(siamese_val_dataset,\n",
    "                            shuffle=False,\n",
    "                            num_workers=8,\n",
    "                            batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    net = SiameseNetwork().cuda()\n",
    "    criterion = ContrastiveLoss()\n",
    "\n",
    "    best_loss = 9999\n",
    "    best_loss_epoch = 0\n",
    "    cumul_epochs = 0\n",
    "\n",
    "    mean_loss_contrastive_list = []\n",
    "    best_loss_contrastive_list = []\n",
    "    validation_loss_list = []\n",
    "    continue_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if not do_skip:\n",
    "    n_epochs = 500\n",
    "    early_stopping_tolerance = 50\n",
    "    optimizer = optim.Adam(net.parameters(),lr = 0.0005)\n",
    "\n",
    "    if continue_training:\n",
    "        mean_loss_contrastive_list = mean_loss_contrastive_list.tolist()\n",
    "        best_loss_contrastive_list = best_loss_contrastive_list.tolist()\n",
    "        validation_loss_list = validation_loss_list.tolist()\n",
    "\n",
    "    print(f\"Starting round of training from epoch {cumul_epochs}\")\n",
    "\n",
    "    for epoch in tqdm(range(0, n_epochs), desc='Epochs'): \n",
    "        # Training loop\n",
    "        net.train()\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            img0, img1, label = data\n",
    "            img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output1, output2 = net(img0, img1)\n",
    "            loss_contrastive = criterion(output1, output2, label)\n",
    "            loss_contrastive.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate mean loss for contrastive loss during training\n",
    "        mean_loss_contrastive = criterion.get_mean_loss()\n",
    "        mean_loss_contrastive_list.append(mean_loss_contrastive)\n",
    "        \n",
    "        # Validation loop\n",
    "        net.eval()  # Set the model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, val_data in enumerate(val_dataloader, 0):\n",
    "                val_img0, val_img1, val_label = val_data\n",
    "                val_img0, val_img1, val_label = val_img0.cuda(), val_img1.cuda(), val_label.cuda()\n",
    "                val_output1, val_output2 = net(val_img0, val_img1)\n",
    "                val_loss += criterion(val_output1, val_output2, val_label).item()\n",
    "\n",
    "        val_loss /= len(val_dataloader)\n",
    "        validation_loss_list.append(val_loss)\n",
    "        #print(f\"Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "        # Check if current loss is the best so far\n",
    "        if val_loss < best_loss:\n",
    "            print(f\"Epoch number {cumul_epochs} --- Best loss {val_loss:.2f}\")\n",
    "            best_loss = val_loss\n",
    "            best_loss_epoch = cumul_epochs\n",
    "            torch.save(net.state_dict(), os.path.join(save_embeddings_path, 'best_model.pt'))\n",
    "        else:\n",
    "            if cumul_epochs - best_loss_epoch > early_stopping_tolerance:\n",
    "                print(f\"Early stopping at epoch {cumul_epochs}\")\n",
    "                best_loss_contrastive_list.append(best_loss)\n",
    "                cumul_epochs +=1\n",
    "                break    \n",
    "        \n",
    "        best_loss_contrastive_list.append(best_loss)\n",
    "        cumul_epochs +=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "    np.save(os.path.join(save_embeddings_path, f'mean_loss_contrastive_list_{take}.npy'), mean_loss_contrastive_list)\n",
    "    np.save(os.path.join(save_embeddings_path, f'best_loss_contrastive_list_{take}.npy'), best_loss_contrastive_list)\n",
    "    np.save(os.path.join(save_embeddings_path, f'validation_loss_list_{take}.npy'), validation_loss_list)\n",
    "    print(f\"Losses saved in {save_embeddings_path} ({take})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_plot:\n",
    "\n",
    "    mean_loss_contrastive_list = np.load(os.path.join(save_embeddings_path, f'mean_loss_contrastive_list_{take}.npy'))\n",
    "    best_loss_contrastive_list = np.load(os.path.join(save_embeddings_path, f'best_loss_contrastive_list_{take}.npy'))\n",
    "    validation_loss_list = np.load(os.path.join(save_embeddings_path, f'validation_loss_list_{take}.npy'))\n",
    "\n",
    "    continue_training=True\n",
    "\n",
    "    %matplotlib inline\n",
    "    plt.ioff()\n",
    "    plt.close('all')\n",
    "    show_plot(range(0,len(mean_loss_contrastive_list)),mean_loss_contrastive_list, title='Training Loss')\n",
    "    show_plot(range(0,len(best_loss_contrastive_list)),validation_loss_list, title='Val Loss')\n",
    "    show_plot(range(0,len(best_loss_contrastive_list)),best_loss_contrastive_list, title='Best Val Loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD MODEL and Test (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "do_skip = False\n",
    "if not do_skip:\n",
    "    # LOAD BEST MODEL\n",
    "    net = SiameseNetwork().cuda()\n",
    "    checkpoint_path = os.path.join(save_embeddings_path, 'best_model.pt')\n",
    "\n",
    "    # Load state dictionary into model\n",
    "    net.load_state_dict(torch.load(checkpoint_path))\n",
    "    net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "siamese_tot_IXI_dataset = SiameseNetworkDataset(images_array=np.concatenate((X_train, X_val), axis=0),\n",
    "                                                labels_array=np.concatenate((y_train, y_val), axis=0),\n",
    "                                                transform=transforms.ToTensor(),\n",
    "                                                test_mode=True,\n",
    "                                                mode='single')\n",
    "\n",
    "siamese_tot_IXI_dataloader = DataLoader(siamese_tot_IXI_dataset,\n",
    "                                shuffle=False,\n",
    "                                num_workers=8,\n",
    "                                batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Pre-allocate memory for the embeddings array\n",
    "num_samples = len(siamese_tot_IXI_dataset)\n",
    "embedding_size = 128  # Assuming the size of the embeddings is 128, adjust as necessary\n",
    "img_embeddings = np.empty((num_samples, embedding_size))\n",
    "print(f\"Number of samples: {num_samples} (batch size: {batch_size}) ==> Passages: {num_samples // batch_size + 1}\")\n",
    "\n",
    "start_idx = 0\n",
    "\n",
    "for img in tqdm(siamese_tot_IXI_dataloader):\n",
    "    img0 = img.cuda()\n",
    "    output = net(img0, None, mode='single').cpu().detach().numpy()\n",
    "    # Calculate the end index for the current batch\n",
    "    end_idx = start_idx + output.shape[0]\n",
    "    # Store the batch of embeddings in the pre-allocated array\n",
    "    img_embeddings[start_idx:end_idx] = output    \n",
    "    # Update the start index for the next batch\n",
    "    start_idx = end_idx\n",
    "        \n",
    "\n",
    "np.save(os.path.join(save_embeddings_path, f'img_embeddings_IXI_{take}.npy'), img_embeddings)\n",
    "print(f\"Image Embeddings saved in {save_embeddings_path}/img_embeddings_IXI_{take}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IXI_img_embeddings = np.load(os.path.join(save_embeddings_path, f'img_embeddings_IXI_{take}.npy'))\n",
    "print(f\"IXI Image Embeddings loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not do_skip:\n",
    "    \n",
    "    # Perform t-SNE clustering\n",
    "    #Peplexity 500\n",
    "    #early_exaggeration=40\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    IXI_img_embeddings_tsne = tsne.fit_transform(IXI_img_embeddings)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(IXI_img_embeddings_tsne[:, 0], IXI_img_embeddings_tsne[:, 1], s=1)\n",
    "    plt.title('Image Clustering Results (t-SNE img_embedding)')\n",
    "\n",
    "    # save the embeddings\n",
    "    np.save(os.path.join(save_embeddings_path,f'img_embeddings_tsne_AIXI_{take}.npy'), IXI_img_embeddings_tsne)\n",
    "    print(f\"TSNE img_embeddings saved in {os.path.join(save_embeddings_path,f'img_embeddings_tsne_AIXI_{take}.npy')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IXI_img_embeddings_tsne = np.load(os.path.join(save_embeddings_path,f'img_embeddings_tsne_AIXI_{take}.npy'))\n",
    "print(f\"TSNE img_embeddings loaded\")\n",
    "print(f\"TSNE img_embeddings shape: {IXI_img_embeddings_tsne.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "if do_plot:\n",
    "    interactive_plot(IXI_img_embeddings_tsne[:, 0], IXI_img_embeddings_tsne[:, 1], colors=None, action='click', img_list=img_list_np, emb_list=IXI_img_embeddings, true_img_list=img_list_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters_img = 50\n",
    "\n",
    "if not do_skip:\n",
    "    # Create a KMeans object with the desired number of clusters\n",
    "    kmeans = KMeans(n_clusters=n_clusters_img, random_state=42, n_init='auto')\n",
    "\n",
    "    # Fit the KMeans model to the img_embeddings\n",
    "    kmeans.fit(IXI_img_embeddings)\n",
    "\n",
    "    # Get the cluster labels for each data point\n",
    "    IXI_img_cluster_labels = kmeans.labels_\n",
    "    print(f\"Classes: {set(IXI_img_cluster_labels)}\")\n",
    "    np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_AIXI_{take}.npy'), IXI_img_cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IXI_img_cluster_labels = np.load(os.path.join(save_embeddings_path,f'img_cluster_labels_AIXI_{take}.npy'))\n",
    "print(f\"Cluster labels loaded\")\n",
    "print(f\"Cluster labels shape: {IXI_img_cluster_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_plot:\n",
    "    interactive_plot(IXI_img_embeddings_tsne[:, 0], IXI_img_embeddings_tsne[:, 1], colors=IXI_img_cluster_labels, action='click', img_list=img_list_np, emb_list=IXI_img_embeddings, true_img_list=img_list_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test CAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable \n",
    "from torchvision import transforms\n",
    "do_skip = False\n",
    "if not do_skip:\n",
    "    siamese_testset = SiameseNetworkDataset(images_array=X_test,\n",
    "                                            labels_array=y_test,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            test_mode=True,\n",
    "                                            metadata=metadata)\n",
    "\n",
    "    CAS_metadata = siamese_testset.get_test_metadata()\n",
    "    print(f\"Saving metadata for CAS dataset: {CAS_metadata}\")\n",
    "    np.save(os.path.join(save_embeddings_path,f'metadata_{dataset_test_name}_{take}.npy'), CAS_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAS_metadata = np.load(os.path.join(save_embeddings_path,f'metadata_{dataset_test_name}_{take}.npy'))\n",
    "print(f\"Metadata loaded for CAS dataset: {CAS_metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_skip:\n",
    "\n",
    "    # Assuming batch_size is now set to something greater than 1\n",
    "    batch_size = 32\n",
    "\n",
    "    siamese_testset = SiameseNetworkDataset(\n",
    "        images_array=X_test,\n",
    "        labels_array=y_test,\n",
    "        transform=transforms.ToTensor(),\n",
    "        test_mode=True,\n",
    "        metadata=metadata,\n",
    "        mode='single'\n",
    "    )\n",
    "\n",
    "    test_dataloader = DataLoader(siamese_testset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    # Pre-allocate memory for the embeddings array\n",
    "    num_samples = len(siamese_testset)\n",
    "    embedding_size = 128  # Assuming the size of the embeddings is 128, adjust as necessary\n",
    "    img_embeddings = np.empty((num_samples, embedding_size))\n",
    "    print(f\"Number of samples: {num_samples} (batch size: {batch_size}) ==> Passages: {num_samples // batch_size + 1}\")\n",
    "\n",
    "    start_idx = 0\n",
    "\n",
    "    for img in tqdm(test_dataloader):\n",
    "        img0 = img.cuda()\n",
    "        output = net(img0, None, mode='single').cpu().detach().numpy()\n",
    "        # Calculate the end index for the current batch\n",
    "        end_idx = start_idx + output.shape[0]\n",
    "        # Store the batch of embeddings in the pre-allocated array\n",
    "        img_embeddings[start_idx:end_idx] = output    \n",
    "        # Update the start index for the next batch\n",
    "        start_idx = end_idx\n",
    "            \n",
    "\n",
    "    np.save(os.path.join(save_embeddings_path, f'img_embeddings_{dataset_test_name}_{take}.npy'), img_embeddings)\n",
    "    print(f\"Image Embeddings saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "if not do_skip:\n",
    "\n",
    "    # Assuming batch_size is now set to something greater than 1\n",
    "    batch_size = 32\n",
    "\n",
    "    siamese_testset = SiameseNetworkDataset(\n",
    "        images_array=X_test,\n",
    "        labels_array=y_test,\n",
    "        transform=transforms.ToTensor(),\n",
    "        test_mode=True,\n",
    "        metadata=metadata,\n",
    "        mode='single'\n",
    "    )\n",
    "\n",
    "    test_dataloader = DataLoader(siamese_testset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    # Pre-allocate memory for the embeddings array\n",
    "    num_samples = len(siamese_testset)\n",
    "    embedding_size = 128  # Assuming the size of the embeddings is 128, adjust as necessary\n",
    "    img_embeddings = np.empty((num_samples, embedding_size))\n",
    "    print(f\"Number of samples: {num_samples} (batch size: {batch_size}) ==> Passages: {num_samples // batch_size + 1}\")\n",
    "\n",
    "    start_idx = 0\n",
    "\n",
    "    for img in tqdm(test_dataloader):\n",
    "        img0 = img.cuda()\n",
    "        output = net(img0, None, mode='single').cpu().detach().numpy()\n",
    "        # Calculate the end index for the current batch\n",
    "        end_idx = start_idx + output.shape[0]\n",
    "        # Store the batch of embeddings in the pre-allocated array\n",
    "        img_embeddings[start_idx:end_idx] = output    \n",
    "        # Update the start index for the next batch\n",
    "        start_idx = end_idx\n",
    "            \n",
    "\n",
    "    np.save(os.path.join(save_embeddings_path, f'img_embeddings_{dataset_test_name}_{take}.npy'), img_embeddings)\n",
    "    print(f\"Image Embeddings saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load img embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_embeddings = np.load(os.path.join(save_embeddings_path, f'img_embeddings_{dataset_test_name}_{take}.npy'))\n",
    "\n",
    "print(f\"img_embeddings loaded from {save_embeddings_path}\")\n",
    "print(f'img_embeddings shape: {img_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLot IMG Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-SNE (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not do_skip:\n",
    "    \n",
    "    # Perform t-SNE clustering\n",
    "    #Peplexity 500\n",
    "    #early_exaggeration=40\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    img_embeddings_tsne = tsne.fit_transform(img_embeddings)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(img_embeddings_tsne[:, 0], img_embeddings_tsne[:, 1], s=1)\n",
    "    plt.title('Image Clustering Results (t-SNE img_embedding)')\n",
    "\n",
    "    # save the embeddings\n",
    "    np.save(os.path.join(save_embeddings_path,f'img_embeddings_tsne_{dataset_test_name}_{take}.npy'), img_embeddings_tsne)\n",
    "    print(f\"TSNE img_embeddings saved in {os.path.join(save_embeddings_path,f'img_embeddings_tsne_{dataset_test_name}_{take}.npy')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_embeddings_tsne = np.load(os.path.join(save_embeddings_path,f'img_embeddings_tsne_{dataset_test_name}_{take}.npy'))\n",
    "print(f\"TSNE img_embeddings loaded\")\n",
    "print(f\"TSNE img_embeddings shape: {img_embeddings_tsne.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "if do_plot:\n",
    "    interactive_plot(img_embeddings_tsne[:, 0], img_embeddings_tsne[:, 1], colors=None, action='click', img_list=X_test_mask, emb_list=img_embeddings, true_img_list=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_plot:\n",
    "    plot_n_patches_overlap(X_test_mask, X_test, indexes=[5597,24,25,26,23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_img = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-MEANS T-SNE (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "if not do_skip:\n",
    "    # Create a KMeans object with the desired number of clusters\n",
    "    kmeans = KMeans(n_clusters=n_clusters_img, random_state=42, n_init='auto')\n",
    "\n",
    "    # Fit the KMeans model to the img_embeddings\n",
    "    kmeans.fit(img_embeddings_tsne)\n",
    "\n",
    "    # Get the cluster labels for each data point\n",
    "    img_cluster_labels_2d = kmeans.labels_\n",
    "    print(f\"Classes: {set(img_cluster_labels_2d)}\")\n",
    "    np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_2d_{dataset_test_name}_{take}.npy'), img_cluster_labels_2d)\n",
    "\n",
    "\n",
    "    # Plot histogram of cluster labels\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(img_cluster_labels_2d)\n",
    "    plt.xlabel('Cluster Label')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Histogram of Cluster Labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cluster_labels_2d = np.load(os.path.join(save_embeddings_path,f'img_cluster_labels_2d_{dataset_test_name}_{take}.npy'))\n",
    "print(f\"Cluster labels loaded\")\n",
    "print(f\"Cluster labels shape: {img_cluster_labels_2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_plot:\n",
    "    interactive_plot(img_embeddings_tsne[:, 0], img_embeddings_tsne[:, 1], colors=img_cluster_labels_2d, action='click', img_list=X_test_mask, emb_list=img_embeddings, true_img_list=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-MEANS with embedding code (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "if not do_skip:\n",
    "    # Create a KMeans object with the desired number of clusters\n",
    "    kmeans = KMeans(n_clusters=n_clusters_img, random_state=42, n_init='auto')\n",
    "\n",
    "    # Fit the KMeans model to the img_embeddings\n",
    "    kmeans.fit(img_embeddings)\n",
    "\n",
    "    # Get the cluster labels for each data point\n",
    "    img_cluster_labels = kmeans.labels_\n",
    "    print(f\"Classes: {set(img_cluster_labels)}\")\n",
    "    np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_{dataset_test_name}_{take}.npy'), img_cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cluster_labels = np.load(os.path.join(save_embeddings_path,f'img_cluster_labels_{dataset_test_name}_{take}.npy'))\n",
    "print(f\"Cluster labels loaded\")\n",
    "print(f\"Cluster labels shape: {img_cluster_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_plot:\n",
    "    plot_2_clusters(img_embeddings_tsne, img_cluster_labels, img_cluster_labels_2d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_plot:\n",
    "    interactive_plot(img_embeddings_tsne[:, 0], img_embeddings_tsne[:, 1], colors=img_cluster_labels, action='click', img_list=X_test_mask, emb_list=img_embeddings, true_img_list=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_plot:\n",
    "    interactive_plot(img_embeddings_tsne[:, 0], img_embeddings_tsne[:, 1], colors=img_cluster_labels, action='click', img_list=X_test_mask, emb_list=img_embeddings, true_img_list=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional to save cluster imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "if do_optional_plots:\n",
    "    pick_colors = 'IMG_2D' # 'IMG_2D' or 'IMG_ND'\n",
    "    add_title = f\"{pick_colors}_{take}\"\n",
    "    # select 10 values at random between 0 and n_cluster\n",
    "    #selected_classes = np.random.choice(n_clusters_img, 1, replace=False)\n",
    "    #selected_classes = range(10)\n",
    "    selected_classes = range(n_clusters_img)\n",
    "\n",
    "\n",
    "    colors = img_cluster_labels_2d if pick_colors == 'IMG_2D' else img_cluster_labels\n",
    "\n",
    "    do = \"filter\" # \"filter\" or \"plot\"\n",
    "\n",
    "    print(f\"Interactive plot filtered over 1 class ({pick_colors} Embedding)\")\n",
    "    for selected_class in tqdm(selected_classes):\n",
    "        print(f\"Selected class: {selected_class}\")\n",
    "        f_img_list, f_emb_list, f_true_img_list, f_indices = interactive_plot_filtered(img_embeddings_tsne[:, 0], img_embeddings_tsne[:, 1], colors=colors, action='click', selected_class=selected_class, img_list=X_test_mask, emb_list=img_embeddings, true_img_list=X_test, do=do)\n",
    "        #plot_slices_with_cursor(f_img_list, f_emb_list, f_true_img_list, cursor_position=10, indeces=f_indices)\n",
    "        \n",
    "        plot_n_patches_overlap(X_test_mask, X_test, indexes=f_indices, selected_class=selected_class, add_title=add_title, m=40, alpha=0.5)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_optional_plots:\n",
    "    interactive_plot(img_embeddings_tsne[:, 0], img_embeddings_tsne[:, 1], colors=img_cluster_labels, action='click', img_list=X_test_mask, emb_list=img_embeddings, true_img_list=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling (NO MORE FROM HERE ON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_lists(*args, indices):\n",
    "#     filtered_lists = []\n",
    "#     for lst in args:\n",
    "#         filtered_lst = [lst[i] for i in indices]\n",
    "#         filtered_lists.append(filtered_lst)\n",
    "#     return filtered_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(*embedding_lists, n_size=1000, random_seed=42):\n",
    "    # Random sampling\n",
    "    np.random.seed(random_seed)\n",
    "    embedding_arrays = [np.array(embedding_list) for embedding_list in embedding_lists]\n",
    "    # Assuming all embedding lists have the same length\n",
    "    num_samples = embedding_arrays[0].shape[0]\n",
    "    \n",
    "    assert len(set(len(embedding_list) for embedding_list in embedding_lists)) == 1, \"All embedding lists should have the same length.\"\n",
    "    \n",
    "    if n_size<1: # percentage of num_samples\n",
    "        print(f\"WARNING: n_size parameter is <1 ({n_size})\")\n",
    "        print(f\"Taking the {n_size*100}% of the num_samples ({num_samples}) ==> {int(n_size * num_samples)}\")\n",
    "        n_size = int(n_size * num_samples)\n",
    "        \n",
    "    # Randomly select indices\n",
    "    random_idx = np.random.choice(num_samples, n_size, replace=False)\n",
    "    # Perform random sampling for each embedding list\n",
    "    random_lists = []\n",
    "    for embedding_array in embedding_arrays:\n",
    "        random_list = embedding_array[random_idx].tolist()\n",
    "        random_lists.append(random_list)\n",
    "    random_lists = [np.array(random_list) for random_list in random_lists]\n",
    "    return random_lists, random_idx\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "def random_class_sampling(*embedding_lists, class_array, n_size=1000, random_seed=42):\n",
    "    # Random sampling\n",
    "    np.random.seed(random_seed)\n",
    "    embedding_arrays = [np.array(embedding_list) for embedding_list in embedding_lists]\n",
    "    \n",
    "    # Assuming all embedding lists have the same length\n",
    "    assert len(set(len(embedding_list) for embedding_list in embedding_lists)) == 1, \"All embedding lists should have the same length.\"\n",
    "    \n",
    "    # Group indices by class\n",
    "    class_indices = {}\n",
    "    class_count = {}\n",
    "    for i, class_label in enumerate(class_array):\n",
    "        if class_label not in class_indices:\n",
    "            class_indices[class_label] = []\n",
    "            class_count[class_label] = 0\n",
    "        class_indices[class_label].append(i)\n",
    "        class_count[class_label]+=1\n",
    "    \n",
    "    # Randomly select indices for each class\n",
    "    random_idx = []\n",
    "    if n_size<1:\n",
    "        # Calculate the number of samples per class (SAME PERCENTAGE FOR EACH CLUSTER)\n",
    "        print(f\"Warning: n_size<1 ({n_size})\")\n",
    "        print(f\"Taking {n_size*100}% of samples for each cluster\")\n",
    "        \n",
    "        if set(class_indices.keys()) == set(class_count.keys()):\n",
    "            # print(\"Keys are the same in both dictionaries\")\n",
    "            for key in class_indices.keys():\n",
    "                indices = class_indices[key]\n",
    "                count_c = class_count[key]\n",
    "                #print(f\"Key: {key}, Value in dict1: {indices}, Value in dict2: {count_c}\")\n",
    "                samples_per_class = int(count_c * n_size)\n",
    "                print(f\"Taking {samples_per_class} for cluster {key}\")\n",
    "                random_idx.extend(np.random.choice(indices, samples_per_class, replace=False))\n",
    "        else:\n",
    "            print(\"Keys are not the same in both dictionaries\")\n",
    "            assert()\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        # Calculate the number of samples per class (SAME NUMBER FOR EACH CLUSTER\n",
    "        samples_per_class = n_size // len(class_indices)\n",
    "        print(f\"Taking {samples_per_class} samples per class\")\n",
    "        for indices in class_indices.values():\n",
    "           random_idx.extend(np.random.choice(indices, samples_per_class, replace=(len(indices) < samples_per_class)))\n",
    "            \n",
    "    \n",
    "    # Perform random sampling for each embedding list\n",
    "    random_lists = []\n",
    "    for embedding_array in embedding_arrays:\n",
    "        random_list = embedding_array[random_idx].tolist()\n",
    "        random_lists.append(random_list)\n",
    "    \n",
    "    random_lists = [np.array(random_list) for random_list in random_lists]\n",
    "    return random_lists, random_idx\n",
    "\n",
    "    \n",
    "    # # Randomly select indices for each class\n",
    "    # class_indices = []\n",
    "    # for embedding_array in embedding_arrays:\n",
    "    #     indices = np.arange(len(embedding_array))\n",
    "    #     np.random.shuffle(indices)\n",
    "    #     class_indices.append(indices[:n_samples_per_class])\n",
    "    \n",
    "    # # Concatenate indices from all classes\n",
    "    # selected_indices = np.concatenate(class_indices)\n",
    "    # np.random.shuffle(selected_indices)\n",
    "    \n",
    "    # # Select samples based on the concatenated indices\n",
    "    # selected_samples = []\n",
    "    # for embedding_array in embedding_arrays:\n",
    "    #     selected_samples.append(embedding_array[selected_indices])\n",
    "    \n",
    "    # return selected_samples, selected_indices\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def farthest_point_sampling(X, num_points, random_seed):\n",
    "    \"\"\"\n",
    "    Perform farthest point sampling to select a subset of points from X.\n",
    "\n",
    "    Parameters:\n",
    "    - X: array-like, shape (n_samples, n_features)\n",
    "        The input data points.\n",
    "    - num_points: int\n",
    "        The number of points to select.\n",
    "\n",
    "    Returns:\n",
    "    - selected_indices: array-like, shape (num_points,)\n",
    "        Indices of the selected points.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an empty list to store selected point indices\n",
    "    selected_indices = []\n",
    "\n",
    "    # Choose a random point to start with\n",
    "    np.random.seed(random_seed)\n",
    "    initial_index = np.random.choice(X.shape[0])\n",
    "    selected_indices.append(initial_index)\n",
    "\n",
    "    # Compute pairwise distances from the selected point to all other points\n",
    "    distances = pairwise_distances(X, [X[initial_index]])\n",
    "\n",
    "    # Iterate until we select num_points\n",
    "    while len(selected_indices) < num_points:\n",
    "        # Find the point farthest from the selected set\n",
    "        farthest_index = np.argmax(distances)\n",
    "\n",
    "        # Update the distances array by choosing the minimum between the existing\n",
    "        # distances and the distances from the newly selected point\n",
    "        distances = np.minimum(distances, pairwise_distances(X, [X[farthest_index]]))\n",
    "\n",
    "        # Add the farthest point to the selected set\n",
    "        selected_indices.append(farthest_index)\n",
    "\n",
    "    return selected_indices\n",
    "\n",
    "def sample_within_class(coordinates, classes, n_size, *arrays, random_seed, single_cluster=False):\n",
    "    \"\"\"\n",
    "    Sample m/p samples from each class using farthest point sampling.\n",
    "    \"\"\"\n",
    "    if single_cluster:\n",
    "        # Consider the whole dataset as a single class\n",
    "        classes = np.zeros_like(classes)\n",
    "    \n",
    "    \n",
    "    unique_classes = np.unique(classes)\n",
    "    sampled_indices = []\n",
    "    if n_size<1:\n",
    "        # Calculate the number of samples per class (SAME PERCENTAGE FOR EACH CLUSTER)\n",
    "        print(f\"Warning: n_size<1 ({n_size})\")\n",
    "        print(f\"Taking {n_size*100}% of samples for each cluster\")\n",
    "        \n",
    "    for c in unique_classes:\n",
    "        # Find indices of samples belonging to class c\n",
    "        class_indices = np.where(classes == c)[0]\n",
    "        num_samples_class = len(class_indices)\n",
    "        \n",
    "        if n_size <1:\n",
    "            samples_to_select = int(n_size*num_samples_class)\n",
    "        else:\n",
    "            samples_to_select = min(n_size // len(unique_classes), num_samples_class)\n",
    "\n",
    "        # Perform farthest point sampling within the class\n",
    "        sampled_indices_class = farthest_point_sampling(coordinates[class_indices], samples_to_select, random_seed=random_seed)\n",
    "        print(f\"Class {c}: {len(sampled_indices_class)} samples selected\")\n",
    "        sampled_indices.extend(class_indices[sampled_indices_class])\n",
    "\n",
    "    # Apply the sampled indices to other arrays\n",
    "    sampled_arrays = [array[sampled_indices] for array in (coordinates, classes) + arrays]\n",
    "\n",
    "    return sampled_arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate some random data points\n",
    "# np.random.seed(0)\n",
    "# X = np.random.rand(100, 2)\n",
    "\n",
    "# # Number of points to select\n",
    "# num_points = 50\n",
    "\n",
    "# # Perform farthest point sampling\n",
    "# X_selected, selected_indices = farthest_point_sampling(X, num_points)\n",
    "# X_randomaaa, random_aaa = random_sampling(X, n_size=num_points)\n",
    "# X_randomaaa = X_randomaaa[0] \n",
    "# print(X_randomaaa.shape)\n",
    "# #plot all X in grey and the selected indices in red\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.scatter(X[:, 0], X[:, 1], color='grey')\n",
    "# plt.scatter(X_selected[:, 0], X_selected[:, 1], color='red')\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.scatter(X[:, 0], X[:, 1], color='grey')\n",
    "# plt.scatter(X_randomaaa[:, 0], X_randomaaa[:, 1], color='blue')\n",
    "# plt.scatter\n",
    "\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# n = 1000  # Number of samples\n",
    "# p = 1    # Number of classes\n",
    "# m = 200   # Total number of samples to select\n",
    "# coordinates = np.random.rand(n, 2)  # Sample coordinates\n",
    "# classes = np.random.randint(0, p, size=(n, 1))  # Sample classes\n",
    "# # Additional arrays\n",
    "# arrays = [np.random.rand(n, np.random.randint(2, 10)) for _ in range(5)]  # Generating 5 random arrays\n",
    "\n",
    "# sampled_arrays = sample_within_class(coordinates, classes, m, *arrays)\n",
    "# coordinate_filtered, classes_filtered, *other_arrays = sampled_arrays\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plot coordinates in grey\n",
    "# plt.scatter(coordinates[:, 0], coordinates[:, 1], color='grey')\n",
    "\n",
    "# # Plot filtered coordinates with color of filtered classes\n",
    "# for c in np.unique(classes_filtered):\n",
    "#     indices = np.where(classes_filtered == c)[0]\n",
    "#     plt.scatter(coordinate_filtered[indices, 0], coordinate_filtered[indices, 1], label=f'Class {c}')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Img list shape: {X_test.shape}\")\n",
    "print(f\"Mask list shape: {X_test_mask.shape}\\n\")\n",
    "\n",
    "print(f\"Img Embeddings shape: {img_embeddings.shape}\")\n",
    "print(f\"Img Embeddings TSNE shape {img_embeddings_tsne.shape}\")\n",
    "\n",
    "print(f\"Class shape: {img_cluster_labels.shape}\")\n",
    "print(f\"Class 2D shape: {img_cluster_labels_2d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START FROM THIS CELL!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "################################\n",
    "# Modify this parameter to choose the number of patches to be selected\n",
    "# It can be either:\n",
    "# Integer n>=1 (Same number of examples for each clusters)\n",
    "# or \n",
    "# Percentage p=[0,1] (Same percentage of examples for each clusters)\n",
    "\n",
    "n_size = 75/100\n",
    "do_plot = True\n",
    "\n",
    "\n",
    "################################\n",
    "################################\n",
    "if n_size<1:\n",
    "    print(f\"In total {int(X_test.shape[0]*n_size)} samples will be selected\")\n",
    "else:\n",
    "    print(f\"In total {n_size} samples will be selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of the classes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if do_plot:\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    ax[0].hist(img_cluster_labels, bins='auto')\n",
    "    ax[0].set_title('(embedding)')\n",
    "    ax[0].set_xlabel('Class')\n",
    "    ax[0].set_ylabel('Frequency')\n",
    "\n",
    "    ax[1].hist(img_cluster_labels_2d, bins='auto')\n",
    "    ax[1].set_title('(t-SNE embedding 2D)')\n",
    "    ax[1].set_xlabel('Class')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sampling (R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lists_r, selected_indices_r = random_sampling(X_test, X_test_mask, img_embeddings, img_embeddings_tsne ,img_cluster_labels, img_cluster_labels_2d, n_size=n_size, random_seed=42)\n",
    "X_test_r, X_test_mask_r, img_embeddings_r,img_embeddings_tsne_r, img_cluster_labels_r, img_cluster_labels_2d_r = selected_lists_r\n",
    "\n",
    "print(f\"Random X Test shape {X_test_r.shape}\")\n",
    "print(f\"Random X Test Mask shape {X_test_mask_r.shape}\")\n",
    "print(f\"Random Img Embedding shape {img_embeddings_r.shape}\")\n",
    "print(f\"Random Img Embedding 2D shape {img_embeddings_tsne_r.shape}\")\n",
    "print(f\"Random Img Class shape {img_cluster_labels_r.shape}\")\n",
    "print(f\"Random Img Class 2D shape {img_cluster_labels_2d_r.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of the classes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if do_plot:\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    ax[0].hist(img_cluster_labels_r, bins='auto')\n",
    "    ax[0].set_title('(embedding)')\n",
    "    ax[0].set_xlabel('Class')\n",
    "    ax[0].set_ylabel('Frequency')\n",
    "\n",
    "    ax[1].hist(img_cluster_labels_2d_r, bins='auto')\n",
    "    ax[1].set_title('(t-SNE embedding 2D)')\n",
    "    ax[1].set_xlabel('Class')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversity sampling (C) (RANDOM WITHIN THE CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lists_c, selected_indices_c = random_class_sampling(X_test, X_test_mask, img_embeddings, img_embeddings_tsne ,img_cluster_labels, img_cluster_labels_2d,\n",
    "                                                      class_array=img_cluster_labels, n_size=n_size, random_seed=42)\n",
    "X_test_c, X_test_mask_c, img_embeddings_c,img_embeddings_tsne_c, img_cluster_labels_c, img_cluster_labels_2d_c = selected_lists_c\n",
    "\n",
    "print(f\"Class X Test shape {X_test_c.shape}\")\n",
    "print(f\"Class X Test Mask shape {X_test_mask_c.shape}\")\n",
    "print(f\"Class Img Embedding shape {img_embeddings_c.shape}\")\n",
    "print(f\"Class Img Embedding 2D shape {img_embeddings_tsne_c.shape}\")\n",
    "print(f\"Class Img Class shape {img_cluster_labels_c.shape}\")\n",
    "print(f\"Class Img Class 2D shape {img_cluster_labels_2d_c.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of the classes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if do_plot:\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    ax[0].hist(img_cluster_labels_c, bins=n_clusters_img)\n",
    "    ax[0].set_title('(embedding)')\n",
    "    ax[0].set_xlabel('Class')\n",
    "    ax[0].set_ylabel('Frequency')\n",
    "\n",
    "    ax[1].hist(img_cluster_labels_2d_c, bins=n_clusters_img)\n",
    "    ax[1].set_title('(t-SNE embedding 2D)')\n",
    "    ax[1].set_xlabel('Class')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversity Sampling (Furthest) (CF) ==> FPS with latent vector classes and t-sne distance computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_arrays_cf = sample_within_class(img_embeddings_tsne, img_cluster_labels, n_size, X_test_mask, X_test, img_embeddings, img_cluster_labels_2d, random_seed=42)\n",
    "img_embeddings_tsne_cf, img_cluster_labels_cf, X_test_mask_cf, X_test_cf, img_embeddings_cf, img_cluster_labels_2d_cf = sampled_arrays_cf\n",
    "\n",
    "print(f\"Class X Test shape {X_test_cf.shape}\")\n",
    "print(f\"Class X Test Mask shape {X_test_mask_cf.shape}\")\n",
    "print(f\"Class Img Embedding shape {img_embeddings_cf.shape}\")\n",
    "print(f\"Class Img Embedding 2D shape {img_embeddings_tsne_cf.shape}\")\n",
    "print(f\"Class Img Class shape {img_cluster_labels_cf.shape}\")\n",
    "print(f\"Class Img Class 2D shape {img_cluster_labels_2d_cf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of the classes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax = ax.flatten()\n",
    "\n",
    "ax[0].hist(img_cluster_labels_cf, bins=n_clusters_img)\n",
    "ax[0].set_title('(embedding)')\n",
    "ax[0].set_xlabel('Class')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "\n",
    "ax[1].hist(img_cluster_labels_2d_cf, bins=n_clusters_img)\n",
    "ax[1].set_title('(t-SNE embedding 2D)')\n",
    "ax[1].set_xlabel('Class')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving Class-sampled dataset\")\n",
    "#np.save(os.path.join(save_embeddings_path,f'X_test_c_{n_size}_{take}.npy'), X_test_c)\n",
    "#np.save(os.path.join(save_embeddings_path,f'X_test_mask_c_{n_size}_{take}.npy'), X_test_mask_c)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_embeddings_c_{n_size}_{take}.npy'), img_embeddings_c)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_embeddings_tsne_c_{n_size}_{take}.npy'), img_embeddings_tsne_c)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_c_{n_size}_{take}.npy'), img_cluster_labels_c)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_2d_c_{n_size}_{take}.npy'), img_cluster_labels_2d_c)\n",
    "\n",
    "print(\"Saving Class-sampled (F) dataset\")\n",
    "#np.save(os.path.join(save_embeddings_path,f'X_test_cf_{n_size}_{take}.npy'), X_test_cf)\n",
    "#np.save(os.path.join(save_embeddings_path,f'X_test_mask_cf_{n_size}_{take}.npy'), X_test_mask_cf)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_embeddings_cf_{n_size}_{take}.npy'), img_embeddings_cf)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_embeddings_tsne_cf_{n_size}_{take}.npy'), img_embeddings_tsne_cf)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_cf_{n_size}_{take}.npy'), img_cluster_labels_cf)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_2d_cf_{n_size}_{take}.npy'), img_cluster_labels_2d_cf)\n",
    "\n",
    "print(\"Saving Random-sampled dataset\")\n",
    "#np.save(os.path.join(save_embeddings_path,f'X_test_r_{n_size}_{take}.npy'), X_test_r)\n",
    "#np.save(os.path.join(save_embeddings_path,f'X_test_mask_r_{n_size}_{take}.npy'), X_test_mask_r)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_embeddings_r_{n_size}_{take}.npy'), img_embeddings_r)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_embeddings_tsne_r_{n_size}_{take}.npy'), img_embeddings_tsne_r)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_r_{n_size}_{take}.npy'), img_cluster_labels_r)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_2d_r_{n_size}_{take}.npy'), img_cluster_labels_2d_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (CFX) ==> Stratified FPS with both classes and distance computation from latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_arrays_cfx = sample_within_class(img_embeddings, img_cluster_labels, n_size, X_test_mask, X_test, img_embeddings_tsne, img_cluster_labels_2d, random_seed=42)\n",
    "img_embeddings_cfx, img_cluster_labels_cfx, X_test_mask_cfx, X_test_cfx, img_embeddings_tsne_cfx, img_cluster_labels_2d_cfx = sampled_arrays_cfx\n",
    "\n",
    "print(f\"Class X Test shape {X_test_cfx.shape}\")\n",
    "print(f\"Class X Test Mask shape {X_test_mask_cfx.shape}\")\n",
    "print(f\"Class Img Embedding shape {img_embeddings_cfx.shape}\")\n",
    "print(f\"Class Img Embedding 2D shape {img_embeddings_tsne_cfx.shape}\")\n",
    "print(f\"Class Img Class shape {img_cluster_labels_cfx.shape}\")\n",
    "print(f\"Class Img Class 2D shape {img_cluster_labels_2d_cfx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving Class-sampled (CFX) dataset\")\n",
    "#np.save(os.path.join(save_embeddings_path,f'X_test_cfx_{n_size}_{take}.npy'), X_test_cfx)\n",
    "#np.save(os.path.join(save_embeddings_path,f'X_test_mask_cfx_{n_size}_{take}.npy'), X_test_mask_cfx)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_embeddings_cfx_{n_size}_{take}.npy'), img_embeddings_cfx)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_embeddings_tsne_cfx_{n_size}_{take}.npy'), img_embeddings_tsne_cfx)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_cfx_{n_size}_{take}.npy'), img_cluster_labels_cfx)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_2d_cfx_{n_size}_{take}.npy'), img_cluster_labels_2d_cfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPS WHOLE (CFW) ==> FPS on the whole dataset + distance computation over the 2D tsne points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_arrays_cfw = sample_within_class(img_embeddings_tsne, img_cluster_labels, n_size, X_test_mask, X_test, img_embeddings, img_cluster_labels_2d, img_cluster_labels, random_seed=42, single_cluster=True)\n",
    "img_embeddings_tsne_cfw, _ , X_test_mask_cfw, X_test_cfw, img_embeddings_cfw, img_cluster_labels_2d_cfw, img_cluster_labels_cfw = sampled_arrays_cfw\n",
    "\n",
    "print(f\"Class X Test shape {X_test_cfw.shape}\")\n",
    "print(f\"Class X Test Mask shape {X_test_mask_cfw.shape}\")\n",
    "print(f\"Class Img Embedding shape {img_embeddings_cfw.shape}\")\n",
    "print(f\"Class Img Embedding 2D shape {img_embeddings_tsne_cfw.shape}\")\n",
    "print(f\"Class Img Class shape {img_cluster_labels_cfw.shape}\")\n",
    "print(f\"Class Img Class 2D shape {img_cluster_labels_2d_cfw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving Class-sampled (FW) dataset\")\n",
    "#np.save(os.path.join(save_embeddings_path,f'X_test_cfw_{n_size}_{take}.npy'), X_test_cfw)\n",
    "#np.save(os.path.join(save_embeddings_path,f'X_test_mask_cfw_{n_size}_{take}.npy'), X_test_mask_cfw)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_embeddings_cfw_{n_size}_{take}.npy'), img_embeddings_cfw)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_embeddings_tsne_cfw_{n_size}_{take}.npy'), img_embeddings_tsne_cfw)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_cfw_{n_size}_{take}.npy'), img_cluster_labels_cfw)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_2d_cfw_{n_size}_{take}.npy'), img_cluster_labels_2d_cfw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPS WHOLE (CFWX) ==> FPS on the whole dataset + distance computation over the latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_arrays_cfwx = sample_within_class(img_embeddings, img_cluster_labels, n_size, X_test_mask, X_test, img_embeddings_tsne, img_cluster_labels_2d, img_cluster_labels, random_seed=42, single_cluster=True)\n",
    "img_embeddings_cfwx, _ , X_test_mask_cfwx, X_test_cfwx, img_embeddings_tsne_cfwx, img_cluster_labels_2d_cfwx, img_cluster_labels_cfwx = sampled_arrays_cfwx\n",
    "\n",
    "print(f\"Class X Test shape {X_test_cfwx.shape}\")\n",
    "print(f\"Class X Test Mask shape {X_test_mask_cfwx.shape}\")\n",
    "print(f\"Class Img Embedding shape {img_embeddings_cfwx.shape}\")\n",
    "print(f\"Class Img Embedding 2D shape {img_embeddings_tsne_cfwx.shape}\")\n",
    "print(f\"Class Img Class shape {img_cluster_labels_cfwx.shape}\")\n",
    "print(f\"Class Img Class 2D shape {img_cluster_labels_2d_cfwx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving Class-sampled (FWX) dataset\")\n",
    "#np.save(os.path.join(save_embeddings_path,f'X_test_cfwx_{n_size}_{take}.npy'), X_test_cfwx)\n",
    "#np.save(os.path.join(save_embeddings_path,f'X_test_mask_cfwx_{n_size}_{take}.npy'), X_test_mask_cfwx)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_embeddings_cfwx_{n_size}_{take}.npy'), img_embeddings_cfwx)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_embeddings_tsne_cfwx_{n_size}_{take}.npy'), img_embeddings_tsne_cfwx)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_cfwx_{n_size}_{take}.npy'), img_cluster_labels_cfwx)\n",
    "#np.save(os.path.join(save_embeddings_path,f'img_cluster_labels_2d_cfwx_{n_size}_{take}.npy'), img_cluster_labels_2d_cfwx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of the classes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax = ax.flatten()\n",
    "\n",
    "ax[0].hist(img_cluster_labels_cfw, bins=n_clusters_img)\n",
    "ax[0].set_title('(embedding)')\n",
    "ax[0].set_xlabel('Class')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "\n",
    "ax[1].hist(img_cluster_labels_2d_cfw, bins=n_clusters_img)\n",
    "ax[1].set_title('(t-SNE embedding 2D)')\n",
    "ax[1].set_xlabel('Class')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all vs random vs class sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRATIFIED RANDOM CLASS (C)\n",
    "X_test_c = np.load(os.path.join(save_embeddings_path, f'X_test_c_{n_size}_{take}.npy'))\n",
    "X_test_mask_c = np.load(os.path.join(save_embeddings_path, f'X_test_mask_c_{n_size}_{take}.npy'))\n",
    "img_embeddings_c = np.load(os.path.join(save_embeddings_path, f'img_embeddings_c_{n_size}_{take}.npy'))\n",
    "img_embeddings_tsne_c = np.load(os.path.join(save_embeddings_path, f'img_embeddings_tsne_c_{n_size}_{take}.npy'))\n",
    "img_cluster_labels_c = np.load(os.path.join(save_embeddings_path, f'img_cluster_labels_c_{n_size}_{take}.npy'))\n",
    "img_cluster_labels_2d_c = np.load(os.path.join(save_embeddings_path, f'img_cluster_labels_2d_c_{n_size}_{take}.npy'))\n",
    "\n",
    "# STRATIFIED FPS CLASS (CF)\n",
    "X_test_cf = np.load(os.path.join(save_embeddings_path, f'X_test_cf_{n_size}_{take}.npy'))\n",
    "X_test_mask_cf = np.load(os.path.join(save_embeddings_path, f'X_test_mask_cf_{n_size}_{take}.npy'))\n",
    "img_embeddings_cf = np.load(os.path.join(save_embeddings_path, f'img_embeddings_cf_{n_size}_{take}.npy'))\n",
    "img_embeddings_tsne_cf = np.load(os.path.join(save_embeddings_path, f'img_embeddings_tsne_cf_{n_size}_{take}.npy'))\n",
    "img_cluster_labels_cf = np.load(os.path.join(save_embeddings_path, f'img_cluster_labels_cf_{n_size}_{take}.npy'))\n",
    "img_cluster_labels_2d_cf = np.load(os.path.join(save_embeddings_path, f'img_cluster_labels_2d_cf_{n_size}_{take}.npy'))\n",
    "\n",
    "# RANDOM TOTAL (R)\n",
    "X_test_r = np.load(os.path.join(save_embeddings_path, f'X_test_r_{n_size}_{take}.npy'))\n",
    "X_test_mask_r = np.load(os.path.join(save_embeddings_path, f'X_test_mask_r_{n_size}_{take}.npy'))\n",
    "img_embeddings_r = np.load(os.path.join(save_embeddings_path, f'img_embeddings_r_{n_size}_{take}.npy'))\n",
    "img_embeddings_tsne_r = np.load(os.path.join(save_embeddings_path, f'img_embeddings_tsne_r_{n_size}_{take}.npy'))\n",
    "img_cluster_labels_r = np.load(os.path.join(save_embeddings_path, f'img_cluster_labels_r_{n_size}_{take}.npy'))\n",
    "img_cluster_labels_2d_r = np.load(os.path.join(save_embeddings_path, f'img_cluster_labels_2d_r_{n_size}_{take}.npy'))\n",
    "\n",
    "# FPS TOTAL (CFW)\n",
    "X_test_cfw = np.load(os.path.join(save_embeddings_path, f'X_test_cfw_{n_size}_{take}.npy'))\n",
    "X_test_mask_cfw = np.load(os.path.join(save_embeddings_path, f'X_test_mask_cfw_{n_size}_{take}.npy'))\n",
    "img_embeddings_cfw = np.load(os.path.join(save_embeddings_path, f'img_embeddings_cfw_{n_size}_{take}.npy'))\n",
    "img_embeddings_tsne_cfw = np.load(os.path.join(save_embeddings_path, f'img_embeddings_tsne_cfw_{n_size}_{take}.npy'))\n",
    "img_cluster_labels_cfw = np.load(os.path.join(save_embeddings_path, f'img_cluster_labels_cfw_{n_size}_{take}.npy'))\n",
    "img_cluster_labels_2d_cfw = np.load(os.path.join(save_embeddings_path, f'img_cluster_labels_2d_cfw_{n_size}_{take}.npy'))\n",
    "\n",
    "# --------- # In all the FPS above the classes are computer through the k-means on the latent vector but the FPS distance is computer through the 2D-TSNE points # --------- #\n",
    "\n",
    "# FPS TOTAL (distance over latent vector) CFWX EXPLANATION\n",
    "\n",
    "# X_test_cfwx = np.load(os.path.join(save_embeddings_path, f'X_test_cfwx_{n_size}_{take}.npy'))\n",
    "# X_test_mask_cfwx = np.load(os.path.join(save_embeddings_path, f'X_test_mask_cfwx_{n_size}_{take}.npy'))\n",
    "# img_embeddings_cfwx = np.load(os.path.join(save_embeddings_path, f'img_embeddings_cfwx_{n_size}_{take}.npy'))\n",
    "# img_embeddings_tsne_cfwx = np.load(os.path.join(save_embeddings_path, f'img_embeddings_tsne_cfwx_{n_size}_{take}.npy'))\n",
    "# img_cluster_labels_cfwx = np.load(os.path.join(save_embeddings_path, f'img_cluster_labels_cfwx_{n_size}_{take}.npy'))\n",
    "# img_cluster_labels_2d_cfwx = np.load(os.path.join(save_embeddings_path, f'img_cluster_labels_2d_cfwx_{n_size}_{take}.npy'))\n",
    "\n",
    "# (CFX) ==> Stratified FPS with both classes and distance computation from latent vectors\n",
    "X_test_cfx = np.load(os.path.join(save_embeddings_path, f'X_test_cfx_{n_size}_{take}.npy'))\n",
    "X_test_mask_cfx = np.load(os.path.join(save_embeddings_path, f'X_test_mask_cfx_{n_size}_{take}.npy'))\n",
    "img_embeddings_cfx = np.load(os.path.join(save_embeddings_path, f'img_embeddings_cfx_{n_size}_{take}.npy'))\n",
    "img_embeddings_tsne_cfx = np.load(os.path.join(save_embeddings_path, f'img_embeddings_tsne_cfx_{n_size}_{take}.npy'))\n",
    "img_cluster_labels_cfx = np.load(os.path.join(save_embeddings_path, f'img_cluster_labels_cfx_{n_size}_{take}.npy'))\n",
    "img_cluster_labels_2d_cfx = np.load(os.path.join(save_embeddings_path, f'img_cluster_labels_2d_cfx_{n_size}_{take}.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R     ==> RANDOM  +   NO CLASS    (No class)          (RANDOM)\n",
    "# C     ==> RANDOM  +   STRATIFIED  (class from latent) (RANDOM)\n",
    "# CF    ==> FPS     +   STRATIFIED  (class from latent) (FPS Distance from 2D)\n",
    "# CFW   ==> FPS     +   NO CLASS    (No class)          (FPS Distance from 2D)\n",
    "# CFWX  ==> FPS     +   NO CLASS    (No class)          (FPS Distance from latent)\n",
    "# CFX   ==> FPS     +   STRATIFIED  (class from latent) (FPS Distance from latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plot complete test dataset\")\n",
    "print(\"COMPLETE\")\n",
    "interactive_plot(img_embeddings_tsne[:, 0], img_embeddings_tsne[:, 1], colors=img_cluster_labels, action='click', img_list=X_test_mask, emb_list=img_embeddings, true_img_list=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plot random sampled test dataset\")\n",
    "print(\"R\")\n",
    "interactive_plot(img_embeddings_tsne_r[:, 0], img_embeddings_tsne_r[:, 1], colors=img_cluster_labels_r, action='click', img_list=X_test_mask_r, emb_list=img_embeddings_r, true_img_list=X_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plot class sampled test dataset\")\n",
    "print(\"C\")\n",
    "interactive_plot(img_embeddings_tsne_c[:, 0], img_embeddings_tsne_c[:, 1], colors=img_cluster_labels_c, action='click', img_list=X_test_mask_c, emb_list=img_embeddings_c, true_img_list=X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plot class (furthest) sampled test dataset\")\n",
    "print(\"CF\")\n",
    "interactive_plot(img_embeddings_tsne_cf[:, 0], img_embeddings_tsne_cf[:, 1], colors=img_cluster_labels_cf, action='click', img_list=X_test_mask_cf, emb_list=img_embeddings_cf, true_img_list=X_test_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plot whole (furthest) sampled test dataset\")\n",
    "print(\"CFW\")\n",
    "interactive_plot(img_embeddings_tsne_cfw[:, 0], img_embeddings_tsne_cfw[:, 1], colors=img_cluster_labels_cfw, action='click', img_list=X_test_mask_cfw, emb_list=img_embeddings_cfw, true_img_list=X_test_cfw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plot whole (furthest) sampled test dataset\")\n",
    "print(\"CFWX\")\n",
    "interactive_plot(img_embeddings_tsne_cfwx[:, 0], img_embeddings_tsne_cfwx[:, 1], colors=img_cluster_labels_cfwx, action='click', img_list=X_test_mask_cfwx, emb_list=img_embeddings_cfwx, true_img_list=X_test_cfwx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plot whole (furthest) sampled test dataset\")\n",
    "print(\"CFWX\")\n",
    "interactive_plot(img_embeddings_tsne_cfwx[:, 0], img_embeddings_tsne_cfwx[:, 1], colors=img_cluster_labels_cfwx, action='click', img_list=X_test_mask_cfwx, emb_list=img_embeddings_cfwx, true_img_list=X_test_cfwx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plot whole (furthest) sampled test dataset\")\n",
    "print(\"CFX\")\n",
    "interactive_plot(img_embeddings_tsne_cfx[:, 0], img_embeddings_tsne_cfx[:, 1], colors=img_cluster_labels_cfx, action='click', img_list=X_test_mask_cfx, emb_list=img_embeddings_cfx, true_img_list=X_test_cfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Datasaved for {n_size} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
